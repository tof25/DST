%\documentclass[12pt,twoside,openright]{report}
\documentclass[11pt, openright]{report}

% packages
\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[a4paper,
	        width=16cm,
            left=2.5cm,
            top=3cm,
		    height=23.5cm]{geometry}

\usepackage{color}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{tabularx}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{lscape}
\usepackage{array}
\usepackage{multirow}


% some definitions
\def\tb{\textbf}
\def\ti{\em}
\def\sc{\textsc}
\definecolor{dark_green}{rgb}{0,0.6,0}
\renewcommand{\arraystretch}{1.5}

%customize lists
\frenchbsetup{ReduceListSpacing=true, CompactItemize=false}

% for titlepage.
\newcommand{\HRule}{\rule{\linewidth}{.5mm}}

% Hyperref.
\hypersetup{
    backref=true,
    pagebackref=true,
    hyperindex=true,
    colorlinks=true,
    breaklinks=true,
    urlcolor=blue,
    linkcolor=red,
    citecolor=black,
    bookmarks=true,
    bookmarksopen=true
}

\begin{document}

% Title page
\begin{titlepage}
\thispagestyle{empty}

\begin{center}

\includegraphics[width=4cm]{LIFC.pdf} \\[1.5cm]
{\sc {\Large Université de Franche-Comté}} \\[1.5cm]

\HRule \\[.8cm]
\setlength{\baselineskip}{2\baselineskip}
{\huge \bfseries Construction d'un DST : autres propositions} \\[.4cm]
\HRule \\[1.5cm]

{\ti par} Christophe \sc{Enderlin} \\
{\ti le} \today \\[.5cm]

\end{center}
\end{titlepage}

\cleardoublepage
\chapter{Contexte}

\section{Rappel}


Pour mémoire, voici une représentation graphique du déroulement des opérations lors de l'insertion d'un nouveau n\oe ud dans le DST, sans équilibrage de
charge, pour simplifier. (voir page suivante)

\newgeometry{margin=.5cm}
  \begin{figure}
    \centering
    \includegraphics[height=\textheight]{./Images/DST_Arrival.png}
  \end{figure}
\restoregeometry

\section{Situation}

À l'issue de nombreux tests, la première version de mon simulateur a montré son manque de robustesse
: lorsqu'un grand nombre de nouveaux arrivants impactent la même zone du DST à un même moment, les
choses se passent mal.
L'ensemble des problèmes observés semble pouvoir être ramené aux deux points suivants :

\subsection{Le foisonnement des requêtes/réponses se passe mal}

Voici un exemple de cas de figure qui pose problème:

2 n\oe uds intègrent le DST via un même contact:
\begin{itemize}
	\item {\ti Node} 14 $\rightarrow$ {\ti Node} 121 $\rightarrow$ {\ti Node} 42 (intégration rapide, pas de scission requise)
	\item {\ti Node} 249 $\rightarrow$ {\ti Node} 121 $\rightarrow$ {\ti Node} 42 (scissions et ajout d'étage requis)
	\item Alors que {\ti Node} 121 est en attente de {\tt ACK\_{\tt CNX\_REQ}/249}\footnote{Autrement dit, un accusé réception d'une requête de demande de connexion pour le nouveau n\oe ud 249} de 42, il reçoit\\{\tt ACK\_{\tt CNX\_REQ}/14} de 42. Il le
   stocke donc puisque ce n'est pas la réponse qu'il attend.

	\item {\ti Node} 14 ne recevant pas la réponse de 121 reste en '{\tt b}'.
   À ce stade de l'intégration, il fait déjà partie du DST et il reçoit donc {\tt ADD\_STAGE/249} mais il
   ne peut y répondre $\Longrightarrow$ {\ti deadlock}.
   
   \end{itemize}

Comme on le voit, le fait que {\tt ACK\_{\tt CNX\_REQ}/14} soit stocké par 121 pose problème ici.

Un seul process (hébergé par {\ti Node} 121) chargé de l'intégration de deux nouveaux n\oe uds différents
attend deux réponses. Le problème vient alors du fait qu'il ne peut pas traiter les réponses du
premier pendant qu'il est occupé avec le deuxième. Ce mécanisme n'est donc pas correct.

On pense alors à deux solutions possibles:
\begin{inparaenum}[\itshape a\upshape)]
	\item utiliser la fonction {\tt MSG\_comm\_waitany()} de Simgrid
   (elle permet de réagir à une réponse parmi celles attendues)
	\item utiliser plusieurs process dédiés, chacun gérant ses propres requêtes/réponses
\end{inparaenum}.

La deuxième solution semble permettre de bien séparer les tâches, ce qui aurait un double avantage :
arrêter de mélanger les requêtes/réponses pour différents nouveaux arrivants, et présenter une
trace d'exécution plus lisible.

\subsection{L'échec d'une diffusion d'un {\tt SET\_UPDATE} est mal géré}

Pour rappel, lorsque l'arrivée d'un nouveau n\oe ud requiert des scissions, on diffuse un {\tt SET\_UPDATE}
sur l'ensemble du sous-arbre impacté dans le but de placer un verrou (l'état '{\tt u}') sur l'ensemble de
ses n\oe uds. Ainsi, les seules requêtes qu'ils accepteront seront celles qui concernent cet ajout (les autres
sont soit refusées, soit différées).

Lorsque cette diffusion échoue (parce qu'on tombe sur une partie déjà verrouillée pour un autre
arrivant, par ex.), on se retrouve dans la situation où une partie du sous-arbre a été
verrouillée pour le nouveau n\oe ud courant, et une autre pour un autre nouveau n\oe ud. Il est donc
important de remettre les choses en état (ôter les verrous posés par la diffusion en échec) pour ne
pas bloquer les choses.

Les tests ont montré que la méthode utilisée pour cela n'est pas correcte puisqu'on arrive à générer des {\ti deadlocks}, les deux sous-arbres se bloquant mutuellement.

Il faut donc trouver des solutions pour ces deux problèmes.

%TODO : parler du mécanisme de CS_REQ et placer des liens dans le texte

\chapter{Foisonnement des messages : solution}

\paragraph {Principes de base:} 

\begin{itemize}
	\item Chaque demande d'insertion de nouveau n\oe ud ({\tt CNX\_REQ}) est traitée par un process distinct créé pour
    l'occasion
	\item Ce sous-process ne peut pas recevoir de réponses à des requêtes qu'il n'a pas émises.
    Dit autrement, il peut (et doit) traiter immédiatement toutes les réponses reçues.
    (plus besoin de différer ou de refuser)
	\item Plusieurs nouveaux n\oe uds utilisant le même contact ne pouvant pas être traités simultanément,
    un mécanisme de file d'attente pour les traiter séquentiellement est mis en place.
\end{itemize}  

De plus, j'ai fait le choix d'utiliser aussi un tel sous-processus pour les diffusions de {\tt SPLIT} et
de {\tt CS\_REQ} parce que là encore, cela semble être un avantage de ne pas mélanger les réponses
attendues dans le cas de diffusions croisées.

Le schéma général de cette solution à process multiples est présenté figure \ref{call_seq} - page \pageref{call_seq}.

\begin{figure}
	\centering
    \includegraphics[scale=.6]{./Images/Call_procs.png}
    \caption{Séquence d'appels des sous-process}
    \label{call_seq}
\end{figure}

\paragraph {Remarque préliminaire:}
\hyperlink{LaunchForkProcess}{{\tt launch\_fork\_process()}} est une fonction chargée de choisir comment exécuter les requêtes qui lui
sont transmises. Elle les confie soit à un nouveau process (cas de {\tt CNX\_REQ}, {\tt BR\_SPLIT}, {\tt BR\_CS\_REQ}),
soit au process courant.

\paragraph {Explications:}
On utilise au plus trois process par n\oe ud.
\begin{enumerate}
	\item {\tt Main\_Proc}
    \begin{itemize}
    	\item il se charge des initialisations et de la création du process {\tt Tasks\_Queue} (qui tourne
          tout le temps de la simulation).
    	\item il héberge les files {\ti tasks\_queue} (les tâches {\tt CNX\_REQ} reçues en attente de traitement) et {\ti delayed\_tasks} (les tâches différées)
        \item
        \begin{inparaenum}[\itshape a\upshape)]
        	lorsqu'il reçoit une requête,
        	\item soit il la place dans la file {\ti tasks\_queue} (cas des {\tt CNX\_REQ}),
        	\item soit il la transmet à \hyperlink{LaunchForkProcess}{{\tt launch\_fork\_process()}},
        	\item soit il la place dans la file {\ti delayed\_tasks}. %(TODO : à vérifier)
        \end{inparaenum}
        \item il héberge ses propres files {\ti async\_answers} et {\ti sync\_answers} (les réponses asynchrones et
          synchrones attendues aux requêtes qu'il a émises)
      \end{itemize}

    \item {\tt Tasks\_Queue}

      Ce process est chargé d'exécuter la fonction \hyperlink{RunTasksQueue}{{\tt run\_tasks\_queue()}} qui traite les files
      {\ti tasks\_queue} et {\ti delayed\_tasks}.
      Il héberge aussi ses propres files {\ti async\_answers} et {\ti sync\_answers}.

    \item {\tt Handle\_Task}
    
      C'est ce process qui est éventuellement créé par \hyperlink{LaunchForkProcess}{{\tt launch\_fork\_process()}} depuis \hyperlink{RunTasksQueue}{{\tt run\_tasks\_queue()}} pour traiter les
      requêtes concernées.
      Il héberge aussi ses propres files {\ti async\_answers} et {\ti sync\_answers}.
\end{enumerate}

\section{Les fonctions de base}

\hypertarget{RunTasksQueue}{}
\subsection {run\_tasks\_queue()}
Voir figure \ref{fig:rtq} - page \pageref{fig:rtq}.

La file {\ti tasks\_queue} contient toutes les demandes de connection (c'est à dire toutes les tâches
{\tt CNX\_REQ}) reçues par le n\oe ud qui héberge cette file. {\tt run\_tasks\_queue()} est donc chargée de traiter
les requêtes présentes dans cette file, par ordre de priorité. \footnote{voir plus loin les \hyperlink{Priorite}{remarques} à ce sujet}

Après avoir traité les tâches différées (voir détails \hyperlink{RunDelayedTasks}{{\tt run\_delayed\_tasks()}} plus loin), on s'occupe de
la file {\ti tasks\_queue} proprement dite, à condition d'être actif (à l'état '{\tt a}').

Le n\oe ud courant possède deux variables "de n\oe ud" (c'est à dire globales à tous les process
hébergés par ce n\oe ud) :
\begin{itemize}[$\bullet$]
	\item{\ti Run\_state} :
Chaque requête de cette file sera traitée par un process distinct, mais il n'est pas possible ici
d'insérer plus d'un nouveau n\oe ud à la fois et il faut donc que ces process s'exécutent
séquentiellement. C'est la raison d'être de cette variable {\ti Run\_state} : pour s'occuper de la tâche
suivante, la tâche courante doit être terminée. (valeur {\ti IDLE})

	\item{\ti Last\_return} :
Cette variable contient la valeur de retour de l'exécution courante de\\{\tt connection\_request()}.

Il y a deux sortes d'échec d'insertion possibles.
Lors de l'arrivée d'un nouveau n\oe ud, on a la séquence d'appels suivante : {\ti nouveau n\oe ud} $\rightarrow
contact \rightarrow leader$. En cas d'échec, le contact doit refaire une tentative plus tard, mais son leader
peut avoir changé entre temps. Le leader doit donc dépiler la requête alors que le contact doit la
conserver dans sa file {\ti tasks\_queue}. Deux valeurs de retour en cas d'échec sont alors requises : un leader
retourne la valeur {\ti FAILED} alors qu'un contact retournera la valeur {\ti UPDATE\_NOK}.
\end{itemize}

Comme on peut le voir, dans le cas général (i.e. $cpt < MAX\_CNX$), une valeur de retour {\ti UPDATE\_NOK}
laisse la requête dans la file pour une nouvelle tentative un peu plus tard ("\emph{Sleep for a while}").
Dans le cas contraire, on dépile pour passer à la requête suivante. (On voit donc qu'en cas de
retour {\ti FAILED}, la requête est bien dépilée.)

\newgeometry{margin=.3cm}
  \begin{figure}
    \centering
    \includegraphics[height=.95\textheight]{./Images/Algo_run_tasks_queue.png}
    \caption{Algo {\tt run\_tasks\_queue()}}
    \label{fig:rtq}
  \end{figure}
\restoregeometry

\paragraph{En détails}\hfill

À l'issue de l'exécution de {\tt connection\_request()}, une réponse est envoyée à l'émetteur seulement
dans les cas où la requête est ici dépilée.

Lors d'un échec, voici alors ce qu'il se passe dans la séquence de retour $leader \rightarrow contact \rightarrow$
{\ti nouveau n\oe ud}: le leader reçoit {\ti FAILED} comme valeur de retour de {\tt connection\_request()},
il dépile donc sa requête et répond {\ti UPDATE\_NOK} à son contact.
Celui-ci ne dépile rien et ne répond pas à {\ti nouveau n\oe ud}. La requête restant dans la file s'exécutera
alors au plus {\ti MAX\_CNX} fois.

Si ce nombre est atteint, on décide alors de dépiler tout de même la requête et de répondre
{\ti UPDATE\_NOK} au nouveau n\oe ud. Il peut ainsi détecter l'échec et refaire d'autres tentatives avec
d'autres contacts. (ces contacts sont alors choisis aléatoirement parmi les n\oe uds déjà intégrés au
DST. Il s'agit d'un tableau global, donc introduisant un peu de centralisation dans cet algorithme.
\footnote {Voir détails plus bas})

Que la file soit dépilée ou pas, elle est à nouveau triée par ordre de priorité à ce moment-là. En
effet, pendant le temps d'exécution de {\tt connection\_request()}, d'autres demandes d'insertion ont pu arriver dans la
file et il faut s'assurer que la prochaine à exécuter soit bien la suivante en termes de priorité.

L'exécution d'une requête de la file est confiée à \hyperlink{LaunchForkProcess}{{\tt launch\_fork\_process()}} (voir plus haut)

\hypertarget{Priorite}{}
\paragraph{À propos de l'ordre d'exécution des tâches dans {\ti tasks\_queue}}\hfill

Dans le cas particulier de la simulation réalisée avec Simgrid, le contact de chaque nouveau n\oe ud est choisi
aléatoirement parmi les nouveaux n\oe uds précédents. Mais au moment où ils sont utilisés comme contact, rien ne garanti
qu'ils soient déjà intégrés au DST. S'ils ne le sont pas, les demandes d'insertion sont remises à plus tard et chaque insertion retardée retarde d'autant l'insertion des n\oe uds qui en dépendent. On aboutit alors à un empilement important des requêtes qui peut se traduire par un temps de simulation trop long, voire même à des blocages.

Afin d'éviter au maximum ce cas de figure, il est donc important, pour une file donnée, de traiter les demandes de connexion des
nouveaux n\oe uds par ordre de priorité. Pour réaliser cela, un
numéro de priorité est attribué à chaque nouveau n\oe ud lors de son arrivée. Cette priorité est utilisée à deux moments :
lors du tri des files {\ti tasks\_queue} selon cet ordre, et lors d'un conflit
(deux requêtes pour deux nouveaux n\oe uds différents sont re\c cues par le même n\oe ud), on laisse passer
en priorité celui qui a le numéro le plus petit.

\paragraph{Un peu de centralisation}\hfill

Dans le même ordre d'idée, on surveille le nombre de tentatives d'insertion d'un nouveau n\oe ud.
S'il devient trop important, on fourni à ce nouveau n\oe ud un nouveau contact, provenant, cette fois, d'une
liste de n\oe uds déjà intégrés au DST. Cette liste devant être accessible à l'ensemble des n\oe uds, il s'agit d'une donnée globale, donc centralisée.

Le but de ce mécanisme étant juste d'améliorer le comportement du simulateur même et pas de valider les
algorithmes du DST proprement dits, je pense qu'on peut raisonnablement le laisser en place sans remettre en cause le
caractère décentralisé de ces algorithmes.

%TODO : Ecrire algo de la partie TASK_{\tt CNX\_REQ} de handle_task()

\hypertarget{RunDelayedTasks}{}
\subsection {run\_delayed\_tasks()}

Voir figures \ref{del-1} et \ref{del-2} - pages \pageref{del-1} et \pageref{del-2}.

Cette fonction est chargée de traiter la file des tâches différées ({\ti delayed\_tasks}). Lorsqu'une tâche
ne peut pas être exécutée par un n\oe ud, soit elle est refusée (charge alors à l'émetteur de réitérer sa demande plus tard), soit
elle est stockée dans cette file pour être exécutée plus tard. Cette fonction est donc appelée
périodiquement. (depuis \hyperlink{RunTasksQueue}{{\tt run\_tasks\_queue()}})

On distingue deux cas : soit le n\oe ud courant est à l'état '{\tt u}', soit il est à '{\tt a}'.

\paragraph {état '{\tt u}'} (voir partie 1 - figure \ref{del-1} - page \pageref{del-1})

Variables:
\begin{itemize}
	\item {\ti nb\_elems} : contient le nombre d'éléments de la file au lancement de {\tt run\_delayed\_tasks()}

	\item {\ti cpt}      : itérateur (de $0$ à {\ti nb\_elems})
\end{itemize}

Un nouveau n\oe ud est alors en cours d'insertion et il faut examiner ce cas en premier pour minimiser
les risques de blocages.
Les seules tâches exécutables ici sont celles qui pourraient permettre de terminer cette insertion,
c'est à dire les {\tt CNX\_GROUPS} pour le même nouveau n\oe ud que celui en cours d'insertion.
(c'est le test {\tt task.args.new\_node\_id == state.new\_node\_id})

On parcourt donc la file à la recherche de ces tâches pour les exécuter. ({\tt handle\_task(task)})

  \begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{./Images/Algo_run_delayed_tasks-1.png}
    \caption{Algo {\tt run\_delayed\_tasks()} - Partie 1}
    \label{del-1}
  \end{figure}

Lorsqu'on en trouve une, on peut l'ôter de la file sans se soucier si son exécution a réussi ou pas
puisque si elle échoue, elle est à nouveau stockée dans la file.

\tb{À noter :} à l'issue de la fonction {\tt handle\_tasks()}, le nombre de tâches de la file a pu augmenter.
Pourtant, on choisi de ne pas mettre à jour la variable {\ti nb\_elems} ici pour ne pas risquer une boucle
sans fin. Si des tâches ont été ajoutées entre temps, elles seront traitées lors d'une prochaine
exécution de {\tt run\_delayed\_tasks()}.

\paragraph {état 'a'} (voir partie 2 - figure \ref{del-2} - page \pageref{del-2})


Ici, le n\oe ud courant est prêt à exécuter n'importe quelle autre tâche et on peut traiter le reste de
la file.

Variables:
\begin{itemize}
	\item {\ti nb\_elems} : le nombre d'éléments restants de la file.
                            %N'est pas non plus remis à jour en cours de boucle.

    \item {\ti idx}       : itérateur (de 0 à {\ti nb\_elems})

    \item {\ti is\_contact} : vaut 1 si le n\oe ud courant est le contact direct du nouveau n\oe ud.
                              (autrement dit, si l'émetteur de la tâche à exécuter est le nouveau n\oe ud)

    \item {\ti buf\_new\_node\_id} : {\tt task.args.new\_node\_id} est mémorisé dans cette variable parce qu'on en a besoin
                                     après la destruction de task.
\end{itemize}\hfill \\
On ôte la tâche courante de la file dans les cas suivants :
\begin{itemize}
	\item l'exécution a réussi ({\ti OK} et {\ti UPDATE\_OK})
    \item la tâche a été stockée à nouveau ({\ti STORED})
    \item l'exécution a échoué mais le n\oe ud courant n'est pas le contact direct du nouveau n\oe ud.
          ({\tt UPDATE\_NOK \&\& !is\_contact})
          Il s'agit du cas {\ti FAILED} décrit plus haut.
\end{itemize}\hfill \\
%*********************************************************************
%TODO : ne pourrait-on pas utiliser FAILED ici plutôt que is_contact ?
%*********************************************************************
\tb{À noter :} si le n\oe ud courant était verrouillé pour le même nouveau n\oe ud que
celui dont la tâche vient d'échouer, alors on ôte le verrou.\footnote{Il s'agit d'ôter ce verrou au plus tôt,
voir explications sur le \hyperlink{CsReq}{verrou} plus loin.}

%*****************
%TODO : pourquoi ?
%*****************

À l'issue de l'exécution de cette boucle ({\tt idx == nb\_elems}), si tout s'est bien passé ({\tt val\_ret == OK}), on choisi de parcourir à nouveau la file jusqu'à ce que {\ti nb\_elems} soit nul. C'est à dire jusqu'à ce qu'on ait ôté de la file autant de requêtes qu'elle en contenait au début de l'exécution de {\tt run\_delayed\_tasks()}.
Comme déjà indiqué, les tâches qui auraient éventuellement été stockées dans la file entre temps seront traitées lors d'une prochaine exécution de {\tt run\_delayed\_tasks()}.

\newgeometry{hmargin=0.5cm, top=.5cm, height=26cm}
  \begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{./Images/Algo_run_delayed_tasks-2.png}
    \caption{Algo {\tt run\_delayed\_tasks()} - Partie 2}
    \label{del-2}
  \end{figure}
\restoregeometry

%*************************************************************************************************
%TODO : se pourrait-il qu'il y ait un nouveau risque de boucle ici si une tâche échoue toujours ?
%       ne faudrait-il pas repérer ce cas ?
%*************************************************************************************************
\hypertarget{LaunchForkProcess}{}
\subsection{launch\_fork\_process()}

Voir figure \ref{lfp} - page \pageref{lfp}.

\begin{figure}
	\centering
    \includegraphics[width=\textwidth]{./Images/Algo_launch_fork_process.png}
    \caption{Algo {\tt launch\_fork\_process()}}
    \label{lfp}
\end{figure}

Si la tâche transmise à cette fonction n'est ni une demande de connexion ({\tt CNX\_REQ}), ni une
diffusion de {\tt SPLIT} ou de {\tt CS\_REQ}, alors elle est exécutée localement, c'est à dire par le process
courant. Sinon, elle est confiée à un nouveau process créé pour l'occasion.

Ce nouveau process doit posséder ses propres files d'attente de réponses attendues ({\ti async\_answers} et
{\ti sync\_answers}) de sorte qu'elles ne puissent plus être mélangées avec celles requises pour l'insertion
d'un autre nouveau n\oe ud.
%\restoregeometry

Il est labelisé ainsi : {\tt xxx-nom\_process-yyy} où :
\begin{itemize}
	\item {\tt xxx} est l'id du n\oe ud courant
	\item {\tt nom\_process} est le nom attribué par cette fonction (tel que "{\tt Cnx\_req}" ou "{\tt Br\_split}", etc)
	\item {\tt yyy} est l'id du nouveau n\oe ud en cours d'insertion
\end{itemize}
On s'assure ainsi de l'unicité de l'étiquette de ce process.

Dans le cas où la tâche est une diffusion de {\tt CS\_REQ} (demande d'entrée en section critique), on
commence par s'assurer que le n\oe ud courant est disponible (c'est à dire répondrait favorablement à
un {\tt CS\_REQ}\footnote{Voir explications sur les \hyperlink{CsReq}{verrous} plus loin.}) pour ne pas créer de process
fils inutilement. En cas de non disponibilité, il faut en informer l'émetteur de la requête.

\section{Les fonctions de communication}

\hypertarget{SendMsgSync}{}
\subsection{synchrone - {\tt send\_msg\_sync()}}

La requête synchrone est utilisée lorsqu'une réponse est attendue pour poursuivre l'exécution du
programme.

Cas d'emplois principaux: \footnote{Pour simplifier, la phase d'équilibrage de charge est ignorée ici.}
\begin{itemize}
	\item {\tt CNX\_REQ} ( fonction {\tt join()} )
  La réponse attendue est la table de routage du contact qui a réussi l'insertion du nouveau n\oe ud

	\item {\tt BROADCAST} ( fonction {\tt handle\_task(): BROADCAST} )
  La réponse attendue ici est la valeur de retour de la fonction {\tt handle\_task()}, c'est à dire le succès  ou l'échec de la requête diffusée.
\end{itemize}

De plus, on utilise aussi ce type de requête pour retransmettre au leader les requêtes {\tt CNX\_REQ} et {\tt SPLIT\_REQ}. \footnote{Pas forcément utile dans le cas de {\tt SPLIT\_REQ}, à voir.}

L'attente de la réponse ne devant pas être bloquante, toutes les requêtes ou autres réponses
arrivant dans l'intervalle doivent être traitées.

\subsubsection{Déroulement simplifié des opérations}

L'émetteur de la requête appelle {\tt send\_msg\_sync()} qui exécute les tâches suivantes :
\begin{itemize}
	\item crée la requête
	\item encapsule la requête dans une tâche
	\item empile la requête sur {\ti sync\_answers}
	\item envoie la tâche au destinataire\\(c'est à dire au process principal {\ti Main proc}  \footnote{voir figure \ref{call_seq}, page \pageref{call_seq}} du n\oe ud destinataire)
	\item attend la réponse\\(sur le process courant qui peut être l'un des process présentés sur la figure \ref{call_seq}, page \pageref{call_seq})
	\item traite tout ce qui est reçu qui n'est pas la réponse
	\item dès que la réponse est reçue, dépile la requête de {\ti sync\_answers}
	\item retourne la réponse à l'appelant
\end{itemize}

\subsubsection{Dans le détail}

La fonction {\tt send\_msg\_sync()} est chargée d'envoyer une requête à un autre n\oe ud, puis d'en attendre
la réponse.

Chaque process hébergé par un n\oe ud possède deux files : {\ti sync\_answers} et {\ti async\_answers}.

Ces deux files servent à stocker les requêtes synchrones et asynchrones (respectivement) émises, le temps qu'elles reçoivent une réponse et qu'elle soit lue. Ces requêtes sont dépilées dès que leur
réponse a été prise en compte.
\footnote{Pour mémoire, la réponse à une requête synchrone contient les données demandées alors que la réponse
à une requête asynchrone est simplement un accusé réception.}

Lorsqu'une réponse est reçue, il y a trois possibilités :
\begin{enumerate}
	\item il s'agit de \tb {la réponse attendue} :
  Dans ce cas, la réponse est prise en compte, la requête correspondante est dépilée et
  le programme se poursuit.

	\item il s'agit d'\tb {une autre réponse attendue} :
  Elle est alors enregistrée dans la bonne pile, avec la requête correspondante, et on se remet en écoute.

	\item il ne s'agit d'\tb {aucune réponse attendue} :
  Elle est simplement ignorée (cas de certains accusés réception, par exemple)
\end{enumerate}

\paragraph{Première partie}envoi de la requête (Voir figure \ref{sms1} - page \pageref{sms1})

Après avoir construit la tâche contenant la requête, celle-ci est envoyée au moyen de la fonction
{\tt isend()} de Simgrid, puis stockée dans la pile {\ti sync\_answers} du process courant.
On attend ensuite la fin de la communication.

Deux traitements différents des cas d'échecs :
\begin{itemize}
	\item la communication ne se termine pas (cas du \tb{process} destinataire arrêté) ou elle a le statut
  {\tt MSG\_TRANSFER\_FAILURE} (cas de l'\tb{hôte} destinataire arrêté) :
  La fonction s'arrête en retournant une erreur de transmission.

	\item la communication se termine avec le statut {\tt TIMEOUT} ( cas d'un destinataire trop occupé, par
  exemple ) :
  On recommence l'émission un certain nombre de fois ({\ti loop\_cpt}).
  Si {\ti max\_loops} est atteint, la fonction est également arrêtée avec une erreur de transmission.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[scale=.5]{./Images/Algo_send_msg_sync-1.png}
    \caption{Algo {\tt send\_msg\_sync()} - Partie 1}
    \label{sms1}
\end{figure}

\paragraph{Deuxième partie} réception de la réponse\\
(Voir figures \ref{sms2} et \ref{sms3} - pages \pageref{sms2} et \pageref{sms3})

Dans cette partie, le \emph{process courant} se met en écoute de la réponse. En cas d'erreur de communication
( {\tt res != MSG\_OK} ), on la signale et on se remet en écoute, sauf s'il s'agit d'un {\tt TIMEOUT} pour une
requête {\tt GET\_REP}.  \footnote{{\tt GET\_REP} demande à un
n\oe ud de fournir un autre représentant moins chargé pour un étage donné. S'il met trop de temps à
répondre et qu'on abandonne, ça n'a pas d'autre conséquence que de conserver le même représentant. On évite ainsi un éventuel {\ti deadlock}}
Dans ce cas, on arrête la fonction là en retournant simplement l'erreur pour la
signaler à l'appelant.

Deux types de tâches peuvent être reçus : soit une requête, soit une réponse.
\begin{description}
	\item [Requête:]
  	Si c'est une demande de connexion ({\tt CNX\_REQ}), elle est simplement stockée dans {\ti tasks\_queue}.
	\footnote{On rappelle que cette file est hébergée par le n\oe ud courant.}
	Sinon, on l'exécute avec {\tt handle\_task()}.% ( TODO : pourquoi pas {\tt launch\_fork\_process} ? )

	Ensuite, on regarde dans la pile {\ti sync\_answers} pour voir si la réponse attendue n'a pas été reçue
	entre temps. Si oui, elle est dépilée et on quitte la boucle de réception. Sinon, on se remet en écoute.

	\item [Réponse :]
  	On commence par regarder s'il s'agit de la réponse synchrone attendue. Si oui, la requête correspondante est dépilée et on
	quitte la boucle de réception.
	Sinon, il peut s'agir d'une autre réponse attendue (synchrone ou asynchrone). Autrement dit, la requête
	correspondante à cette réponse est trouvée dans une des deux piles {\ti sync\_answers} ou {\ti async\_answers}.
	Dans ce cas, la réponse est enregistrée avec sa requête dans sa pile et on se remet en écoute.
	S'il ne s'agit d'aucune réponse attendue, on peut l'ignorer simplement et se remettre en écoute.
\end{description}

\paragraph{Remarques}
\begin{enumerate}
	\item Dans cette fonction, la requête en attente de réponse se trouve toujours au sommet de la pile du fait de ces trois éléments :
	\begin{itemize}
		\item une pile {\ti sync\_answers} donnée n'est associée qu'à un seul process.
		\item un process donné ne peut exécuter qu'une seule instance de {\tt send\_msg\_sync()} à la fois
		\item {\tt send\_msg\_sync()} est la seule fonction susceptible d'empiler une requête dans {\ti sync\_answers}
	\end{itemize}
	De ce fait, lorsqu'on reçoit une réponse à une requête synchrone attendue, il est facile de déterminer
	s'il s'agit de la réponse attendue ou d'une autre : la requête est au sommet de la pile ou pas.

	\item Si {\tt send\_msg\_sync()} n'est pas appelée par le process principal, elle ne peut pas recevoir d'autre
	message que celui qui est attendu.
\end{enumerate}

\newgeometry{top=0cm, right=0cm, width=21cm, height=29.7cm}
\begin{landscape}
  \begin{figure}[h]
    \centering
    \includegraphics[height=\textheight]{./Images/Algo_send_msg_sync-2.png}
    \caption{Algo {\tt send\_msg\_sync()} - Partie 2}
    \label{sms2}
  \end{figure}
\end{landscape}
\restoregeometry

\begin{figure}
	\centering
    \includegraphics[scale=.5]{./Images/Algo_send_msg_sync-3.png}
    \caption{Algo {\tt send\_msg\_sync()} - Partie 3}
    \label{sms3}
\end{figure}

\hypertarget{SendMsgAsync}{}
\subsection{asynchrone - {\tt send\_msg\_async()}}

Dans ce type de requête, le destinataire renvoie un simple accusé réception à l'émetteur une fois la
requête demandée effectuée. Ces accusés réception seront pris en compte ou pas selon les besoins de synchronisation.

Dans les deux cas, les opération se déroulent ainsi :
l'émetteur appelle {\tt send\_msg\_async(}) qui exécute les tâches suivantes :
\begin{itemize}
	\item crée la requête
	\item encapsule la requête dans une tâche
	\item envoie la tâche au destinataire (\emph {i.e.} au process principal du destinataire, comme {\tt send\_msg\_sync()})
\end{itemize}

Puis deux cas se présentent :
\begin{description}
	\item[Un accusé réception est attendu -]
	Cas des requêtes suivantes :
	\begin{itemize}
		\item {\tt BROADCAST} ( fonction {\tt broadcast()} )
		\item {\tt NEW\_BROTHER\_RCV} ( fonction {\tt connection\_request()} )
		\item {\tt DEL\_PRED} ( fonctions {\tt connect\_splitted\_groups()}, {\tt split()} )
		\item {\tt ADD\_PRED} ( fonction {\tt connect\_splitted\_groups()} )
		\item {\tt CNX\_GROUPS} ( fonction {\tt split()} )
	\end{itemize}

	L'émetteur empile alors la requête sur {\ti async\_answers} puis, lorsque plusieurs requêtes ont été émises,
	il appelle \hyperlink{WaitForCompletion}{{\tt wait\_for\_completion()}} pour arrêter le déroulement du programme jusqu'à ce que l'ensemble
	des accusés réception ait été reçu. \footnote{voir détails de {\tt wait\_for\_completion()} plus loin}
	C'est cette fonction qui dépile les requêtes de {\ti async\_answers} au fur et à mesure de leur réception
	et comme \hyperlink{SendMsgSync}{{\tt send\_msg\_sync()}}, elle traite aussi tout ce qu'elle reçoit entre temps.


	\item[Pas d'accusé réception -]
	Dans ce cas, l'appelant ne fait qu'exécuter {\tt send\_msg\_async()}.
\end{description}


\subsubsection{En détails}
Voir figure \ref{sma} - page \pageref{sma}.

Cette fonction réalise la même chose que la première partie de  \hyperlink{SendMsgSync}{{\tt send\_msg\_sync()}}, à la différence qu'on
n'empile pas la requête puisqu'on laisse le soin à l'émetteur de décider s'il faut le faire ou pas.

Une autre différence est qu'on ignore un éventuel défaut d'émission ({\tt res != MSG\_OK}) alors que le
programme est arrêté dans  \hyperlink{SendMsgSync}{{\tt send\_msg\_sync()}}. Ce n'est pas volontaire, je n'ai juste pas encore étudié
la tolérance aux pannes.

\begin{figure}
    \centering
    \includegraphics[height=.95\textheight]{./Images/Algo_send_msg_async.png}
    \caption{Algo {\tt send\_msg\_async()}}
    \label{sma}
\end{figure}


\hypertarget{WaitForCompletion}{}
\subsection{asynchrone - {\tt wait\_for\_completion()}}

Voir figure \ref{wfc} - page \pageref{wfc}.

On attend {\ti ans\_cpt} réponses\footnote{Sur le process courant qui peut être l'un de ceux qui est présenté sur la figure \ref{call_seq} page \pageref{call_seq}}. Si {\ti max\_wait} est atteint avant que toutes les réponses aient été reçues
et traitées, on quitte sur erreur, ce cas ne devant pas se produire.

{\tt wait\_for\_completion()} pouvant s'appeler elle-même, il faut commencer par vérifier si des réponses
attendues ont déjà été traitées par ces appels récursifs, et s'il en reste encore à traiter.
C'est l'appel à \hyperlink{CheckAsyncNok}{{\tt check\_async\_nok()}} du début.

Si oui, on se met en écoute, et comme dans  \hyperlink{SendMsgSync}{{\tt send\_msg\_sync()}}, il faut traiter tout ce qui est reçu
dans l'intervalle:

\begin{description}

	\item[Requête:]

  Si c'est {\tt CNX\_REQ}, on l'empile sur {\ti tasks\_queue}, sinon, on l'exécute avec\\\hyperlink{LaunchForkProcess}{{\tt launch\_fork\_process()}}.
  On regarde ensuite si des réponses ont été reçues entre temps avec \hyperlink{CheckAsyncNok}{{\tt check\_async\_nok()}}, puis on se
  remet éventuellement en écoute.

	\item[Réponse:]\hfill
	
	\begin{itemize}[$\bullet$]

		\item Réponse asynchrone correspondant à une requête empilée :
		\begin{itemize}
			\item si elle fait partie de celles qui sont attendues, la requête correspondante est dépilée
           d'{\ti async\_answers}, après avoir mémorisé un éventuel échec de {\tt BROADCAST} ou {\tt SET\_UPDATE} dans {\ti ret}
           (pour du log).\footnote{On ne mémorise ici que le premier échec}
           On se remet ensuite en écoute s'il reste des réponses à recevoir. ({\tt ans\_cpt > 0})

           \item sinon, elle est enregistrée dans {\ti async\_answers}
    	\end{itemize}

		\item Réponse synchrone attendue :
		\begin{itemize}
	    	\item si oui, elle est enregistrée dans {\ti sync\_answers}
 			\item sinon, elle est ignorée.  %TODO : ce cas ne devrait pas se produire
    	\end{itemize}
    
    \end{itemize}
\end{description}
    
\begin{landscape}
\newgeometry{top=0cm, left=0cm, width=29.7cm, height=21cm}
\begin{figure}
    \centering
    \includegraphics[height=.93\textheight]{./Images/Algo_wait_for_completion.png}
    \caption{Algo {\tt wait\_for\_completion()}}
    \label{wfc}
\end{figure}
\restoregeometry
\end{landscape}

\hypertarget{CheckAsyncNok}{}
\subsection{asynchrone - {\tt check\_async\_nok()}}

Voir figure \ref{can} - page \pageref{can}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{./Images/Algo_check_async_nok.png}
    \caption{Algo {\tt check\_async\_nok()}}
    \label{can}
\end{figure}

Cette fonction auxiliaire est appelée par \hyperlink{WaitForCompletion}{{\tt wait\_for\_completion()}}. Elle est chargée de parcourir la file
{\ti async\_answers} à la recherche de réponses re\c cues.
Le cas échéant, la requête correspondante est retirée de la pile, le compteur de réponses attendues
{\ti ans\_cpt} est ajusté et on retourne également la dernière erreur re\c cue.

%***********************************************************************************************************************************

\chapter{Échec d'une diffusion d'un verrou : solution}
\hypertarget{CsReq}{}

\paragraph{Rappel du problème}\hfill

Lorsqu'il est nécessaire de faire de la place pour un nouveau n\oe ud, on diffuse
une requête sur l'ensemble du sous-arbre impacté pour y poser un verrou.
Cette diffusion peut échouer pour différentes raisons (si elle rencontre une autre
diffusion semblable pour un autre nouveau n\oe ud, par exemple). Dans ce cas,
cette diffusion doit non seulement s'arrêter, mais il faut aussi ôter les verrous qu'elle a déjà
posés sous peine de blocage mutuel des diffusions en conflit.

La solution proposée dans la version précédente du simulateur consistait à relancer
une nouvelle diffusion destinée cette fois à ôter les verrous posés. Dans la pratique,
on constate que cette façon de faire n'est pas la bonne : elle génère un grand nombre
de diffusions qui s'entrecroisent et peuvent causer des blocages, sans parler du nombre
de messages que cela génère. Il faut donc trouver une autre solution.

\paragraph{Idée de solution}\hfill

En premier lieu, pour diminuer le nombre de messages échangés lors de ces diffusions,
elles ne vont plus couvrir que les leaders. En effet, il suffit d'interroger un leader
pour savoir si la voie est libre ou pas.

Ensuite, l'idée générale de cette nouvelle proposition est de procéder en deux temps:
\begin{enumerate}
	\item diffuser une première requête que j'appelle {\tt CS\_REQ}\footnote{Demande
d'entrée en section critique}\\
	Cette diffusion ne pose pas de verrou mais positionne simplement des variables qui sont
	capables de revenir à leur état initial en cas d'échec, sans nouvelle diffusion.

	\item si cette diffusion s'est bien passée, diffuser la pose de verrou proprement
dit -- requête {\tt SET\_UPDATE}
\end{enumerate}

\section{Solution détaillée}
\subsection{Fonction {\tt cs\_req()}}

Chaque n\oe ud possède un ensemble de variables d'état pour ce mécanisme:
\begin{quote}
\begin{description}
	\item [{\ti cs\_req}:] Flag qui indique si une demande a été reçue ou pas
	\item [{\ti cs\_req\_time}:] Heure à laquelle la demande a été reçue
	\item [{\ti cs\_new\_id}:] Id du nouveau n\oe ud pour lequel la demande a été faite
	\item [{\ti cs\_new\_node\_prio}:] Niveau de priorité du nouveau n\oe ud
\end{description}
\end{quote}\hfill

Cette fonction prend les arguments suivants:
\begin{quote}
\begin{description}
	\item [{\ti new\_node\_id}:] C'est l'id du nouveau n\oe ud en cours d'insertion
	\item [{\ti cs\_new\_node\_prio}:] La priorité de ce nouveau n\oe ud
\end{description}
\end{quote}
Et elle est décrite à la figure \ref{csr} page \pageref{csr}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{./Images/Algo_cs_req.png}
    \caption{Algo {\tt cs\_req()}}
    \label{csr}
\end{figure}

{\ti test} est un flag qui passe à 1 s'il s'est écoulé plus de {\tt MAX\_CS\_REQ} unités de temps
depuis la dernière fois qu'une demande a été vue.

\begin{itemize}[$\bullet$]

	\item Pla\c cons nous dans le cas où aucune demande n'a été re\c cue : {\tt me.cs\_req} vaut alors {\tt 0}.
Les deux premiers tests valent {\tt non} et si on est à l'état {\tt 'a'}, on va
positionner les variables de n\oe ud indiquant qu'une demande a été re\c cue\footnote{Autrement dit, on se met en situation
d'accepter la pose de verrou qui suivra, qui doit arriver avant que {\tt MAX\_CS\_REQ} soit écoulé}:
	\begin{itemize}
		\item {\tt me.cs\_req} passe à 1
		\item {\tt me.cs\_new\_id} re\c coit l'argument {\tt new\_node\_id} pour mémoriser le nouveau n\oe ud qui
		a causé cette demande
		\item {\tt me.cs\_req\_time} re\c coit l'heure courante
		\item {\tt me.cs\_new\_node\_prio} mémorise la priorité du nouveau n\oe ud
	\end{itemize} 
	On retourne alors {\tt OK} pour indiquer que tout s'est bien passé, la demande a été acceptée, on est prêt
	à recevoir le verrou correspondant.\\

	\item Si une autre demande est re\c cue avant ce verrou,	voici ce qu'il se passe :\\
	{\tt me.cs\_req} vaut alors {\tt 1} et	on commence par regarder si ce flag doit être remis à {\tt 0}, c'est à dire si:
	\begin{itemize}
		\item cette demande en cours concerne un autre nouveau n\oe ud
		\item on est toujours à l'état {\tt 'a'}\footnote{Si un verrou avait été posé entre temps, on serait à l'état {\tt 'u'}.}
		\item soit le nouveau n\oe ud courant est prioritaire sur celui qui a fait cette demande,
		soit elle est trop ancienne.
	\end{itemize}
	
	Dans ce cas, le flag est à nouveau positionné, mais pour ce nouveau n\oe ud courant. La diffusion du verrou pour le nouveau
	n\oe ud précédent échouera donc.\footnote{Voir détails plus loin}\\
	
	Sinon, si le flag est maintenu à {\tt 1}, on se contente de lire les variables associées pour retourner la bonne réponse :
	on répond {\tt UPDATE\_NOK} si la demande en cours concerne un autre nouveau n\oe ud ou si on n'est plus 
	à l'état {\tt 'a'}. Sinon, on répond {\tt OK} pour dire que tout va bien.

\end{itemize}

\subsection{Diffusion du verrou {\tt SET\_UPDATE}}

Tout d'abord, pour que la diffusion de {\tt SET\_UPDATE} ait lieu, la diffusion de {\tt CS\_REQ}
doit avoir retourné {\tt OK}. Ce qui signifie que l'ensemble des leaders du sous-arbre concerné doit avoir
ses variables {\tt cs\_req} correctement positionnées pour qu'un {\tt SET\_UPDATE} soit accepté.
\footnote{Si le {\tt SET\_UPDATE} re\c cu n'est pas celui qui était attendu, on exécute la fonction
{\tt cs\_req()} localement pour éventuellement positionner différemment les variables {\tt cs\_req}.
Il s'agit de vérifier si on peut l'accepter ou pas.}

Si la diffusion de {\tt CS\_REQ} échoue, aucun verrou n'est posé et comme on l'a vu plus haut,
le fait que les flags aient été positionnés pour une diffusion qui n'aura finalement pas lieu n'est pas bloquant.

Mais on a également vu qu'entre la diffusion de {\tt CS\_REQ} et celle du {\tt SET\_UPDATE}
correspondant, des flags pouvaient avoir changé, ce qui provoquera l'échec de la diffusion de ce {\tt SET\_UPDATE}.
Dans ce cas, il faut tout de même refaire une diffusion d'une tâche {\tt REMOVE\_STATE} chargée de remettre
les leaders concernés dans l'état où ils étaient avant la pose du verrou, tout comme dans la première solution.

\chapter{Comparaison avec la première solution}

\section{Pose des verrous}

Dans la nouvelle solution, il faut deux diffusions ({\tt CS\_REQ} et {\tt SET\_UPDATE}) pour une pose de verrou réussie
contre une seule auparavant. Mais pour un échec, on utilise maintenant soit une seule diffusion ({\tt CS\_REQ}), soit trois
({\tt CS\_REQ}, puis {\tt SET\_UPDATE} et enfin {\tt REMOVE\_STATE}).
\footnote{Il faut tout de même rappeler que ces diffusions sont de toutes fa\c cons moins coûteuses que celles de
l'ancienne version puisque maintenant, on ne diffuse plus qu'aux leaders, au lieu de diffuser à tous les membres
du sous-arbre comme avant.}

Au final, est-ce que cette nouvelle solution consomme moins de bande passante qu'avant ou pas ?

Pour le déterminer, j'ai réalisé les mesures présentées dans le tableau \ref{tab-cpt} : 
\begin{table}[ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
		\cline{3-14}
		\multicolumn{2}{c|}{}& \multicolumn{4}{c|}{1 000 n\oe uds} & \multicolumn{4}{c|}{4 000 n\oe uds} &  \multicolumn{4}{c|}{10 000 n\oe uds}\\
		\cline{3-14}
		\multicolumn{2}{c|}{}& 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4\\
		\hline
		\multirow{2}{*}{BR\_CS\_REQ} & Échecs & 6 989 & 6 417 & 8 653 & 7 424 & 46 926 & 107 691 & 86 602 && 292 025 &&&\\
		\cline{2-14}                 & Succès &   273 &   275  & 277 & 272 & 1 040 & 1 080 & 1 072 && 2 481 &&&\\
		\hline
		\multirow{2}{*}{BR\_SET\_UPDATE} & Échecs & 49 & 52 & 57 & 51 & 174 & 264 & 235 && 508 &&&\\
		\cline{2-14}                     & Succès & 224 & 223 & 220 & 221 & 866 & 816 & 837 && 1 973 &&&\\
		\hline
		\multicolumn{2}{|c|}{BR\_REMOVE\_STATE} & 49 & 52 & 57 & 51 & 174 & 264 & 235  && 508 &&&\\
		\hline
		\multicolumn{2}{|c|}{Nouveau Contact} & 92 & 61 & 147 & 111 & 936 & 3 427 & 2 560 && 12 063 &&&\\ 
		\hline
	\end{tabular}
	\caption{Comptage des Diffusions de Verrou}
	\label{tab-cpt}
\end{table}

J'appelle \emph{échecs coûteux} les échecs de {\tt BR\_SET\_UPDATE} puisqu'ils coûtent 3 diffusions et
\emph{échecs non coûteux} les échecs de {\tt BR\_CS\_REQ} qui ne coûtent qu'une seule diffusion.

On constate alors que les échecs coûteux sont bien moins fréquents que les échecs non coûteux.
D'autre part, ces échecs non coûteux coûtent deux fois moins que ceux de l'ancienne version.

On peut donc penser que cette nouvelle solution consomme moins de bande passante que la précédente.

À noter que j'ai aussi compté le nombre de fois qu'on changeait de contact lors de ces opérations.
Je n'en conclus rien de particulier, si ce n'est le fait que plus on a d'échecs, et plus on tente
avec un autre contact, ce qui est cohérent.


\section{Nouveaux algorithmes}

J'ai pu construire avec ces nouvelles solutions des DST jusqu'à 40 000 n\oe uds (je n'ai pas pu aller plus loin à
cause de la mémoire nécessaire) et je n'ai pas constaté de \emph{deadlocks}.

Contrairement à ma première solution, le simulateur réussi aussi ces constructions même si je change les paramètres
du réseau (augmentation de la latence, par exemple, pour dégrader les performances).

Les performances du simulateur même sont moins bonnes : durée d'exécution plus longue et mémoire nécessaire plus
importante. Cela me paraît normal dans la mesure où les n\oe uds doivent maintenant héberger plusieurs
process en parallèle. De plus, dans l'ancien simulateur, il était très fréquent (bien que j'aie cru le contraire)
que lors de l'arrivée d'un nouveau n\oe ud, les n\oe uds précédents avaient déjà terminé leur intégration.
On était alors souvent dans un cas quasi séquentiel ou les n\oe uds arrivent les uns derrière les autres.
Ici, on simule bien mieux le cas de n\oe uds arrivant simultanément.

\paragraph{Reste à faire}\hfill
\begin{itemize}
	\item voir s'il ne serait pas possible de diminuer la mémoire requise
	\item inclure les algorithmes de départ de n\oe uds dans ces mécanismes
	\item étudier la possibilité, en fin d'exécution de la simulation, de sortir l'ensemble des tables de routage sous la forme d'un fichier (XML, par exemple)
	qui décrirait notre DST et qui pourrait servir de source pour un autre simulateur qui cette fois, simulerait un DST en fonctionnement, et pas
	simplement en construction.
\end{itemize}

\end{document}