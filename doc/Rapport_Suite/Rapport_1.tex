%\documentclass[12pt,twoside,openright]{report}
\documentclass[12pt, openright]{report}

% packages
\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[a4paper,
	        width=16cm,
            left=2.5cm,
            top=3.5cm,
		    height=23cm]{geometry}

\usepackage{color}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{tabularx}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{lscape}


% some definitions
\def\tb{\textbf}
\def\ti{\em}
\def\sc{\textsc}
\definecolor{dark_green}{rgb}{0,0.6,0}

%customize lists
\frenchbsetup{ReduceListSpacing=true, CompactItemize=false}

% for titlepage.
\newcommand{\HRule}{\rule{\linewidth}{.5mm}}

% Hyperref.
\hypersetup{
    backref=true,
    pagebackref=true,
    hyperindex=true,
    colorlinks=true,
    breaklinks=true,
    urlcolor=blue,
    linkcolor=black,
    citecolor=black,
    bookmarks=true,
    bookmarksopen=true
}

\begin{document}

% Title page
\begin{titlepage}
\thispagestyle{empty}

\begin{center}

\includegraphics[width=4cm]{LIFC.pdf} \\[1.5cm]
{\sc {\Large Université de Franche-Comté}} \\[1.5cm]

\HRule \\[.8cm]
\setlength{\baselineskip}{2\baselineskip}
{\huge \bfseries Construction d'un DST : autres propositions} \\[.4cm]
\HRule \\[1.5cm]

{\ti par} Christophe \sc{Enderlin} \\
{\ti le} \today \\[.5cm]

\end{center}
\end{titlepage}

\cleardoublepage
\chapter{Contexte}

\section{Rappel}


Pour mémoire, voici une représentation graphique du déroulement des opérations lors de l'insertion d'un nouveau n\oe ud dans le DST, sans équilibrage de
charge, pour simplifier. (voir page suivante)

\newgeometry{margin=.5cm}
  \begin{figure}
    \centering
    \includegraphics[height=\textheight]{./Images/DST_Arrival.png}
  \end{figure}
\restoregeometry

\section{Situation}

À l'issue de nombreux tests, la première version de mon simulateur a montré son manque de robustesse
: lorsqu'un grand nombre de nouveaux arrivants impactent la même zone du DST à un même moment, les
choses se passent mal.
L'ensemble des problèmes observés semble pouvoir être ramené aux deux points suivants :

\subsection{Le foisonnement des requêtes/réponses se passe mal}

Voici un exemple de cas de figure qui pose problème:

2 n\oe uds intègrent le DST via un même contact:
\begin{itemize}
	\item {\ti Node} 14 $\rightarrow$ {\ti Node} 121 $\rightarrow$ {\ti Node} 42 (intégration rapide, pas de scission requise)
	\item {\ti Node} 249 $\rightarrow$ {\ti Node} 121 $\rightarrow$ {\ti Node} 42 (scissions et ajout d'étage requis)
	\item Alors que {\ti Node} 121 est en attente de {\tt ACK\_{\tt CNX\_REQ}/249}\footnote{Autrement dit, un accusé réception d'une requête de demande de connexion pour le nouveau n\oe ud 249} de 42, il reçoit\\{\tt ACK\_{\tt CNX\_REQ}/14} de 42. Il le
   stocke donc puisque ce n'est pas la réponse qu'il attend.

	\item {\ti Node} 14 ne recevant pas la réponse de 121 reste en '{\tt b}'.
   À ce stade de l'intégration, il fait déjà partie du DST et il reçoit donc {\tt ADD\_STAGE/249} mais il
   ne peut y répondre $\Longrightarrow$ {\ti deadlock}.
   
   \end{itemize}

Comme on le voit, le fait que {\tt ACK\_{\tt CNX\_REQ}/14} soit stocké par 121 pose problème ici.

Un seul process (hébergé par {\ti Node} 121) chargé de l'intégration de deux nouveaux n\oe uds différents
attend deux réponses. Le problème vient alors du fait qu'il ne peut pas traiter les réponses du
premier pendant qu'il est occupé avec le deuxième. Ce mécanisme n'est donc pas correct.

On pense alors à deux solutions possibles:
\begin{inparaenum}[\itshape a\upshape)]
	\item utiliser la fonction {\tt MSG\_comm\_waitany()} de Simgrid
   (elle permet de réagir à une réponse parmi celles attendues)
	\item utiliser plusieurs process dédiés, chacun gérant ses propres requêtes/réponses
\end{inparaenum}.

La deuxième solution semble permettre de bien séparer les tâches, ce qui aurait un double avantage :
arrêter de mélanger les requêtes/réponses pour différents nouveaux arrivants, et présenter une
trace d'exécution plus lisible.

\subsection{L'échec d'une diffusion d'un {\tt SET\_UPDATE} est mal géré}

Pour rappel, lorsque l'arrivée d'un nouveau n\oe ud requiert des scissions, on diffuse un {\tt SET\_UPDATE}
sur l'ensemble du sous-arbre impacté dans le but de placer un verrou (l'état '{\tt u}') sur l'ensemble de
ses n\oe uds. Ainsi, les seules requêtes qu'ils accepteront seront celles qui concernent cet ajout (les autres
sont soit refusées, soit différées).

Lorsque cette diffusion échoue (parce qu'on tombe sur une partie déjà verrouillée pour un autre
arrivant, par exemple), on se retrouve dans la situation où une partie du sous-arbre a été
verrouillée pour le nouveau n\oe ud courant, et une autre pour un autre nouveau n\oe ud. Il est donc
important de remettre les choses en état (ôter les verrous posés par la diffusion en échec) pour ne
pas bloquer les choses.

Les tests ont montré que la méthode utilisée pour cela n'est pas correcte puisqu'on arrive malgré
tout à générer des {\ti deadlocks}, les deux sous-arbres se bloquant mutuellement.

Il faut donc trouver des solutions pour ces deux problèmes.

%TODO : parler du mécanisme de CS_REQ et placer des liens dans le texte

\chapter{Foisonnement des messages : solution}

\paragraph {Principes de base:} 

\begin{itemize}
	\item Chaque demande d'insertion de nouveau n\oe ud ({\tt CNX\_REQ}) est traitée par un process distinct créé pour
    l'occasion
	\item Ce sous-process ne peut pas recevoir de réponses à des requêtes qu'il n'a pas émises.
    Dit autrement, il doit (et peut) traiter immédiatement toutes les réponses reçues.
    (plus besoin de différer ou de refuser)
	\item Plusieurs nouveaux n\oe uds utilisant le même contact ne pouvant pas être traités simultanément,
    un mécanisme de file d'attente pour les traiter séquentiellement est mis en place.
\end{itemize}  

De plus, j'ai fait le choix d'utiliser aussi un tel sous-processus pour les diffusions de {\tt SPLIT} et
de {\tt CS\_REQ} parce que là encore, cela semble être un avantage de ne pas mélanger les réponses
attendues dans le cas de diffusions croisées.

Le schéma général de cette solution à process multiples est présenté figure \ref{call_seq} - page \pageref{call_seq}.

\begin{figure}
	\centering
    \includegraphics[scale=.6]{./Images/Call_procs.png}
    \caption{Séquence d'appels des sous-process}
    \label{call_seq}
\end{figure}

\paragraph {Remarque préliminaire:}
{\tt launch\_fork\_process()} est une fonction chargée de choisir comment exécuter les requêtes qui lui
sont transmises. Elle les confie soit à un nouveau process (cas de {\tt CNX\_REQ}, {\tt BR\_SPLIT}, {\tt BR\_CS\_REQ}),
soit au process courant.

\paragraph {Explications:}
On utilise au plus trois process par n\oe ud.
\begin{enumerate}
	\item {\tt Main\_Proc}
    \begin{itemize}
    	\item il se charge des initialisations et de la création du process {\tt Tasks\_Queue} (qui tourne
          tout le temps de la simulation).
    	\item il héberge les files {\ti tasks\_queue} (les tâches {\tt CNX\_REQ} reçues en attente de traitement) et {\ti delayed\_tasks} (les tâches différées)
        \item
        \begin{inparaenum}[\itshape a\upshape)]
        	lorsqu'il reçoit une requête,
        	\item soit il la place dans la file {\ti tasks\_queue} (cas des {\tt CNX\_REQ}),
        	\item soit il la transmet à {\tt launch\_fork\_process()},
        	\item soit il la place dans la file {\ti delayed\_tasks}. %(TODO : à vérifier)
        \end{inparaenum}
        \item il héberge ses propres files {\ti async\_answers} et {\ti sync\_answers} (les réponses asynchrones et
          synchrones attendues aux requêtes qu'il a émises)
      \end{itemize}

    \item {\tt Tasks\_Queue}

      Ce process est chargé d'exécuter la fonction {\tt run\_tasks\_queue()} qui traite les files
      {\ti tasks\_queue} et {\ti delayed\_tasks}.
      Il héberge aussi ses propres files {\ti async\_answers} et {\ti sync\_answers}.

    \item {\tt Handle\_Task}
    
      C'est ce process qui est éventuellement créé par {\tt launch\_fork\_process()} depuis {\tt run\_tasks\_queue()} pour traiter les
      requêtes concernées.
      Il héberge aussi ses propres files {\ti async\_answers} et {\ti sync\_answers}.
\end{enumerate}

\section{Les fonctions de base}

\label{rtq}
\subsection {run\_tasks\_queue()}
Voir figure \ref{fig:rtq} - page \pageref{fig:rtq}.

La file {\ti tasks\_queue} contient toutes les demandes de connection (c'est à dire toutes les tâches
{\tt CNX\_REQ}) reçues par le n\oe ud qui héberge cette file. {\tt run\_tasks\_queue()} est donc chargée de traiter
les requêtes présentes dans cette file, par ordre de priorité. \footnote{voir plus loin les remarques à ce sujet}

Après avoir traité les tâches différées (voir détails {\tt run\_delayed\_tasks()} plus loin), on s'occupe de
la file {\ti tasks\_queue} proprement dite, à condition d'être actif (à l'état '{\tt a}').

Le n\oe ud courant possède deux variables "de n\oe ud" (c'est à dire globales à tous les process
hébergés par ce n\oe ud) :
\begin{itemize}[$\bullet$]
	\item{\ti Run\_state} :
Chaque requête de cette file sera traitée par un process distinct, mais il n'est pas possible ici
d'insérer plus d'un nouveau n\oe ud à la fois et il faut donc que ces process s'exécutent
séquentiellement. C'est la raison d'être de cette variable {\ti Run\_state} : pour s'occuper de la tâche
suivante, la tâche courante doit être terminée. (valeur {\ti IDLE})

	\item{\ti Last\_return} :
Cette variable contient la valeur de retour de l'exécution courante de {\tt connection\_request()}.

Il y a deux sortes d'échec d'insertion possibles.
Lors de l'arrivée d'un nouveau n\oe ud, on a la séquence d'appels suivante : {\ti nouveau n\oe ud} $\rightarrow
contact \rightarrow leader$. En cas d'échec, le contact doit refaire une tentative plus tard, mais son leader
peut avoir changé entre temps. Le leader doit donc dépiler la requête alors que le contact doit la
conserver dans sa file {\ti tasks\_queue}. Deux valeurs de retour en cas d'échec sont alors requises : un leader
retourne la valeur {\ti FAILED} alors qu'un contact retournera la valeur {\ti UPDATE\_NOK}.
\end{itemize}

Comme on peut le voir, dans le cas général (i.e. $cpt < MAX\_CNX$), une valeur de retour {\ti UPDATE\_NOK}
laisse la requête dans la file pour une nouvelle tentative un peu plus tard ("\emph{Sleep for a while}").
Dans le cas contraire, on dépile pour passer à la requête suivante. (On voit donc qu'en cas de
retour {\ti FAILED}, la requête est bien dépilée.)

\newgeometry{margin=.3cm}
  \begin{figure}
    \centering
    \includegraphics[height=.95\textheight]{./Images/Algo_run_tasks_queue.png}
    \caption{Algo {\tt run\_tasks\_queue()}}
    \label{fig:rtq}
  \end{figure}
\restoregeometry

\paragraph{En détails}\hfill

À l'issue de l'exécution de {\tt connection\_request()}, une réponse est envoyée à l'émetteur seulement
dans les cas où la requête est ici dépilée.

Lors d'un échec, voici alors ce qu'il se passe dans la séquence de retour $leader \rightarrow contact \rightarrow$
{\ti nouveau n\oe ud}: le leader reçoit {\ti FAILED} comme valeur de retour de {\tt connection\_request()},
il dépile donc sa requête et répond {\ti UPDATE\_NOK} à son contact.
Celui-ci ne dépile rien et ne répond pas à {\ti nouveau n\oe ud}. La requête restant dans la file s'exécutera
alors au plus {\ti MAX\_CNX} fois.

Si ce nombre est atteint, on décide alors de dépiler tout de même la requête et de répondre
{\ti UPDATE\_NOK} au nouveau n\oe ud. Il peut ainsi détecter l'échec et refaire d'autres tentatives avec
d'autres contacts. (ces contacts sont alors choisis aléatoirement parmi les n\oe uds déjà intégrés au
DST. Il s'agit d'un tableau global, donc introduisant un peu de centralisation dans cet algorithme.
\footnote {Voir commentaires en conclusion})

Que la file soit dépilée ou pas, elle est à nouveau triée par ordre de priorité à ce moment-là. En
effet, pendant le temps d'exécution de {\tt connection\_request()}, d'autres demandes d'insertion ont pu arriver dans la
file et il faut s'assurer que la prochaine à exécuter soit bien la suivante en termes de priorité.

L'exécution d'une requête de la file est confiée à {\tt launch\_fork\_process()} (voir plus haut)

\paragraph{À propos de l'ordre d'exécution des tâches dans {\ti tasks\_queue}}\hfill

Dans le cas particulier de la simulation réalisée avec Simgrid, le contact de chaque nouveau n\oe ud est choisi
aléatoirement parmi les nouveaux n\oe uds précédents. Au moment où ils sont utilisés comme contact, rien ne garanti
qu'ils soient déjà intégrés au DST. S'ils ne le sont pas, les demandes d'insertion sont remises à plus tard; elles 
ne pourront aboutir que lorsque le contact fera lui-même partie du DST.

Pour une file donnée, il est donc important de respecter l'ordre d'arrivée des demandes de connexion des
nouveaux n\oe uds pour ne pas courir le risque de trop empiler ces demandes. Pour réaliser cela, un
numéro de priorité est attribué à chaque nouveau n\oe ud lors de son arrivée. Cette priorité est utilisée à deux moments :
lors du tri des files {\ti tasks\_queue} selon cet ordre, et lors d'un conflit
(deux requêtes pour deux nouveaux n\oe uds différents sont re\c cues par le même n\oe ud), on laisse passer
en priorité celui qui a le numéro le plus petit.

\paragraph{Un peu de centralisation}\hfill

Dans le même ordre d'idée, on surveille le nombre de tentatives d'insertion d'un nouveau n\oe ud.
S'il devient trop important, on fourni au nouveau n\oe ud un nouveau contact, choisi, cette fois, dans une
liste de n\oe uds déjà intégrés au DST. Cette liste est pour l'instant accessible à l'ensemble des n\oe uds et
il s'agit d'une variable globale, donc centralisée.

Le but de cette man\oe uvre étant juste d'éviter un blocage du simulateur même, et pas de faire fonctionner les
algorithmes du DST proprement dit, je pense qu'on peut raisonnablement le laisser sans remettre en cause le
caractère décentralisé de ces algorithmes.

%TODO : Ecrire algo de la partie TASK_{\tt CNX\_REQ} de handle_task()


\subsection {run\_delayed\_tasks()}
Voir figures \ref{del-1} et \ref{del-2} - pages \pageref{del-1} et \pageref{del-2}.

Cette fonction est chargée de traiter la file des tâches différées ({\ti delayed\_tasks}). Lorsqu'une tâche
ne peut pas être exécutée par un n\oe ud, soit elle est refusée (et retournée à l'émetteur), soit
elle est stockée dans cette file pour être exécutée plus tard. Cette fonction est donc appelée
périodiquement. (Voir {\tt run\_tasks\_queue()})

On distingue deux cas : soit le n\oe ud courant est à l'état '{\tt u}', soit il est à '{\tt a}'.

\paragraph {état '{\tt u}'} (voir partie 1 - figure \ref{del-1} - page \pageref{del-1})

Variables:
\begin{itemize}
	\item {\ti nb\_elems} : contient le nombre d'éléments de la file au lancement de {\tt run\_delayed\_tasks()}

	\item {\ti cpt}      : itérateur (de $0$ à {\ti nb\_elems})
\end{itemize}

Un nouveau n\oe ud est alors en cours d'insertion et il faut examiner ce cas en premier pour minimiser
les risques de blocages.
Les seules tâches exécutables ici sont celles qui pourraient permettre de terminer cette insertion,
c'est à dire les {\tt CNX\_GROUPS} pour le même nouveau n\oe ud que celui en cours d'insertion.
(c'est le test {\tt task.args.new\_node\_id == state.new\_node\_id})

On parcourt donc la file à la recherche de ces tâches pour les exécuter. ({\tt handle\_task(task)})

\newgeometry{hmargin=1cm, top=3.5cm, height=23cm}
  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{./Images/Algo_run_delayed_tasks-1.png}
    \caption{Algo {\tt run\_delayed\_tasks()} - Partie 1}
    \label{del-1}
  \end{figure}

Lorsqu'on en trouve une, on peut l'ôter de la file sans s'assurer que son exécution a réussi ou pas
puisque si elle échoue, elle est à nouveau stockée dans la file.

\tb{À noter :} à l'issue de la fonction {\tt handle\_tasks()}, le nombre de tâches de la file a pu augmenter.
Pourtant, on choisi de ne pas mettre à jour la variable {\ti nb\_elems} ici pour ne pas risquer une boucle
sans fin. Si des tâches ont été ajoutées entre temps, elles seront traitées lors d'une prochaine
exécution de {\tt run\_delayed\_tasks()}.
\restoregeometry

\paragraph {état 'a'} (voir partie 2 - figure \ref{del-2} - page \pageref{del-2})


Ici, le n\oe ud courant est prêt à exécuter n'importe quelle autre tâche et on peut traiter le reste de
la file.

Variables:
\begin{itemize}
	\item {\ti nb\_elems} : le nombre d'éléments restants de la file.
                            %N'est pas non plus remis à jour en cours de boucle.

    \item {\ti idx}       : itérateur (de 0 à {\ti nb\_elems})

    \item {\ti is\_contact} : vaut 1 si le n\oe ud courant est le contact direct du nouveau n\oe ud.
                              (autrement dit, si l'émetteur de la tâche à exécuter est le nouveau n\oe ud)

    \item {\ti buf\_new\_node\_id} : {\tt task.args.new\_node\_id} est mémorisé dans cette variable parce qu'on en a besoin
                                     après la destruction de task.
\end{itemize}\hfill \\
On ôte la tâche courante de la file dans les cas suivants :
\begin{itemize}
	\item l'exécution a réussi ({\ti OK} et {\ti UPDATE\_OK})
    \item la tâche a été stockée à nouveau ({\ti STORED})
    \item l'exécution a échoué mais le n\oe ud courant n'est pas le contact direct du nouveau n\oe ud.
          ({\tt UPDATE\_NOK \&\& !is\_contact})
          Il s'agit du cas {\ti FAILED} décrit plus haut.
\end{itemize}\hfill \\
%*********************************************************************
%TODO : ne pourrait-on pas utiliser FAILED ici plutôt que is_contact ?
%*********************************************************************
\tb{À noter :} si le n\oe ud courant était verrouillé pour le même nouveau n\oe ud que
celui dont la tâche vient d'échouer, alors on ôte le verrou.\footnote{Il s'agit d'ôter ce verrou au plus tôt,
voir explications sur le verrou plus loin.}

%*****************
%TODO : pourquoi ?
%*****************

À l'issue de l'exécution de cette boucle ({\tt idx == nb\_elems}), la file n'est pas forcément vide. Elle
contient toutes les tâches dont l'exécution a échoué et celles qui ont été stockées -- y compris par d'autres
process -- entre temps. Cette boucle est alors à nouveau exécutée jusqu'à ce que {\ti nb\_elems} soit à 0,
c'est dire jusqu'au succès de toutes les tâches qui se trouvaient dans cette file au moment de
cet appel de {\tt run\_delayed\_tasks()}. Comme indiqué précédemment, les tâches ajoutées entre temps ne
seront pas traitées lors de cette exécution.

\newgeometry{hmargin=0.5cm, top=.5cm, height=26cm}
  \begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{./Images/Algo_run_delayed_tasks-2.png}
    \caption{Algo {\tt run\_delayed\_tasks()} - Partie 2}
    \label{del-2}
  \end{figure}
\restoregeometry

%*************************************************************************************************
%TODO : se pourrait-il qu'il y ait un nouveau risque de boucle ici si une tâche échoue toujours ?
%       ne faudrait-il pas repérer ce cas ?
%*************************************************************************************************
\subsection{launch\_fork\_process()} 

Voir figure \ref{lfp} - page \pageref{lfp}.

\begin{figure}
	\centering
    \includegraphics[width=\textwidth]{./Images/Algo_launch_fork_process.png}
    \caption{Algo {\tt launch\_fork\_process()}}
    \label{lfp}
\end{figure}

Si la tâche transmise à cette fonction n'est ni une demande de connexion ({\tt CNX\_REQ}), ni une
diffusion de {\tt SPLIT} ou de {\tt CS\_REQ}, alors elle est exécutée localement, c'est à dire par le process
courant. Sinon, elle est confiée à un nouveau process créé pour l'occasion.

Ce nouveau process doit posséder ses propres files d'attente de réponses attendues ({\ti async\_answers} et
{\ti sync\_answers}) de sorte qu'elles ne puissent plus être mélangées avec celles requises pour l'insertion
d'un autre nouveau n\oe ud.
%\restoregeometry

Il est labelisé ainsi : {\tt xxx-nom\_process-yyy} où :
\begin{itemize}
	\item {\tt xxx} est l'id du n\oe ud courant
	\item {\tt nom\_process} est le nom attribué par cette fonction (tel que "{\tt Cnx\_req}" ou "{\tt Br\_split}", etc)
	\item {\tt yyy} est l'id du nouveau n\oe ud en cours d'insertion
\end{itemize}
On s'assure ainsi de l'unicité de l'étiquette de ce process.

Dans le cas où la tâche est une diffusion de {\tt CS\_REQ} (demande d'entrée en section critique), on
commence par s'assurer que le n\oe ud courant est disponible (c'est à dire répondrait favorablement à
un {\tt CS\_REQ}\footnote{Voir explications sur les verrous plus loin.}) pour ne pas créer de process
fils inutilement. En cas de non-disponibilité, il faut en informer l'émetteur de la requête.

\section{Les fonctions de communication}

\subsection{synchrone - {\tt send\_msg\_sync()}}

La requête synchrone est utilisée lorsqu'une réponse est attendue pour poursuivre l'exécution du
programme.

Cas d'emplois principaux: \footnote{Pour simplifier, la phase d'équilibrage de charge est ignorée ici.}
\begin{itemize}
	\item {\tt CNX\_REQ} ( fonction {\tt join()} )
  La réponse attendue est la table de routage du contact qui a réussi l'insertion du nouveau n\oe ud

	\item {\tt BROADCAST} ( fonction {\tt handle\_task(): BROADCAST} )
  La réponse attendue ici est la valeur de retour de la fonction {\tt handle\_task()}, c'est à dire le succès  ou l'échec de la requête diffusée.
\end{itemize}

De plus, on utilise aussi ce type de requête pour retransmettre au leader les requêtes {\tt CNX\_REQ} et {\tt SPLIT\_REQ}. \footnote{Pas forcément utile dans le cas de {\tt SPLIT\_REQ}, à voir.}

L'attente de la réponse ne devant pas être bloquante, toutes les requêtes ou autres réponses
arrivant dans l'intervalle doivent être traitées.

\subsubsection{Déroulement simplifié des opérations}

L'émetteur de la requête appelle {\tt send\_msg\_sync()} qui exécute les tâches suivantes :
\begin{itemize}
	\item crée la requête
	\item encapsule la requête dans une tâche
	\item empile la requête sur {\ti sync\_answers}	%TODO: c'est pas la tâche plutôt ?
	\item envoie la tâche au destinataire
	\item attend la réponse
	\item traite tout ce qui est reçu qui n'est pas la réponse
	\item dès que la réponse est reçue, dépile la requête de {\ti sync\_answers}
	\item retourne la réponse à l'appelant
\end{itemize}

\subsubsection{Dans le détail}

La fonction {\tt send\_msg\_sync()} est chargée d'envoyer une requête à un autre n\oe ud, puis d'en attendre
la réponse.

Chaque process hébergé par un n\oe ud possède deux files : {\ti sync\_answers} et {\ti async\_answers}.

Ces deux files servent à stocker les requêtes synchrones et asynchrones (respectivement) émises, le temps qu'elles reçoivent une réponse et qu'elle soit lue. Ces requêtes sont dépilées dès que leur
réponse a été prise en compte.
\footnote{Pour mémoire, la réponse à une requête synchrone contient les données demandées alors que la réponse
à une requête asynchrone est simplement un accusé réception.}

Lorsqu'une réponse est reçue, il y a trois possibilités :
\begin{enumerate}
	\item il s'agit de \tb {la réponse attendue} :
  Dans ce cas, la réponse est prise en compte, la requête correspondante est dépilée et
  le process se poursuit.

	\item il s'agit d'\tb {une autre réponse attendue} :
  Elle est alors enregistrée dans la bonne pile, avec la requête correspondante, et on se remet en écoute.

	\item il ne s'agit d'\tb {aucune réponse attendue} :
  Elle est simplement ignorée (cas de certains accusés réception, par exemple)
\end{enumerate}

\paragraph{Première partie}envoi de la requête (Voir figure \ref{sms1} - page \pageref{sms1})

Après avoir construit la tâche contenant la requête, celle-ci est envoyée au moyen de la fonction
{\tt isend()} de Simgrid, puis stockée dans la pile {\ti sync\_answers} du process courant.
On attend ensuite la fin de la communication.

Deux traitements différents des cas d'échecs :
\begin{itemize}
	\item la communication ne se termine pas (cas du \tb{process} destinataire arrêté) ou elle a le statut
  {\tt MSG\_TRANSFER\_FAILURE} (cas de l'\tb{hôte} destinataire arrêté) :
  La fonction s'arrête en retourant une erreur de transmission.

	\item la communication se termine avec le statut {\tt TIMEOUT} ( cas d'un destinataire trop occupé, par
  exemple ) :
  On recommence l'émission un certain nombre de fois ({\ti loop\_cpt}).
  Si {\ti max\_loops} est atteint, la fonction est également arrêtée avec une erreur de transmission.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[scale=.5]{./Images/Algo_send_msg_sync-1.png}
    \caption{Algo {\tt send\_msg\_sync()} - Partie 1}
    \label{sms1}
\end{figure}

\paragraph{Deuxième partie} réception de la réponse\\
(Voir figures \ref{sms2} et \ref{sms3} - pages \pageref{sms2} et \pageref{sms3})

Dans cette partie, le process courant se met en écoute de la réponse. En cas d'erreur de communication
( {\tt res != MSG\_OK} ), on la signale et on se remet en écoute, sauf s'il s'agit d'un {\tt TIMEOUT} pour une
requête {\tt GET\_REP}.  \footnote{{\tt GET\_REP} demande à un
n\oe ud de fournir un autre représentant moins chargé pour un étage donné. S'il met trop de temps à
répondre et qu'on abandonne, ça n'a pas d'autre conséquence que de conserver le même représentant. On évite ainsi un éventuel {\ti deadlock}}
Dans ce cas, on arrête la fonction là en retournant simplement l'erreur pour la
signaler à l'appelant.

Deux types de tâches peuvent être reçus : soit une requête, soit une réponse.
\begin{description}
	\item [Requête:]
  	Si c'est une demande de connexion ({\tt CNX\_REQ}), elle est simplement stockée dans {\ti tasks\_queue}.
	\footnote{On rappelle que cette file est hébergée par le n\oe ud courant.}
	Sinon, on l'exécute avec {\tt handle\_task()}.% ( TODO : pourquoi pas {\tt launch\_fork\_process} ? )

	Ensuite, on regarde dans la pile {\ti sync\_answers} pour voir si la réponse attendue n'a pas été reçue
	entre temps. Si oui, elle est dépilée et on quitte la boucle de réception. Sinon, on se remet en écoute.

	\item [Réponse :]
  	On commence par regarder s'il s'agit de la réponse synchrone attendue. Si oui, elle est dépilée et on
	quitte la boucle de réception.
	Sinon, il peut s'agir d'une autre réponse attendue (synchrone ou asynchrone). Autrement dit, la requête
	correspondante à cette réponse est trouvée dans une des deux piles {\ti sync\_answers} ou {\ti async\_answers}.
	Dans ce cas, la réponse est enregistrée avec sa requête dans sa pile et on se remet en écoute.
	S'il ne s'agit d'aucune réponse attendue, on peut l'ignorer simplement et se remettre en écoute.
\end{description}

\paragraph{Remarques}
\begin{enumerate}
	\item Dans cette fonction, la requête en attente de réponse se trouve toujours au sommet de la pile du fait de ces trois éléments :
	\begin{itemize}
		\item une pile {\ti sync\_answers} n'est associée qu'à un seul process.
		\item un process donné ne peut exécuter qu'une seule instance de {\tt send\_msg\_sync()} à la fois
		\item {\tt send\_msg\_sync()} est la seule fonction susceptible d'empiler une requête dans {\ti sync\_answers}
	\end{itemize}
	De ce fait, lorsqu'on reçoit une réponse à une requête synchrone attendue, il est facile de déterminer
	s'il s'agit de la réponse attendue ou d'une autre : la requête est au sommet de la pile ou pas.

	\item Si {\tt send\_msg\_sync()} n'est pas appelée par le process principal, elle ne peut pas recevoir d'autre
	message que celui qui est attendu.
\end{enumerate}

\newgeometry{top=0cm, right=0cm, width=21cm, height=29.7cm}
\begin{landscape}
  \begin{figure}[h]
    \centering
    \includegraphics[height=\textheight]{./Images/Algo_send_msg_sync-2.png}
    \caption{Algo {\tt send\_msg\_sync()} - Partie 2}
    \label{sms2}
  \end{figure}
\end{landscape}
\restoregeometry

\begin{figure}
	\centering
    \includegraphics[scale=.5]{./Images/Algo_send_msg_sync-3.png}
    \caption{Algo {\tt send\_msg\_sync()} - Partie 3}
    \label{sms3}
\end{figure}

\subsection{asynchrone - {\tt send\_msg\_async()}}

Dans ce type de requête, le destinataire renvoie un simple accusé réception à l'émetteur une fois la
requête demandée effectuée. Ces accusés réception seront pris en compte ou pas selon les besoins de synchronisation.

Dans les deux cas, les opération se déroulent ainsi :
l'émetteur appelle {\tt send\_msg\_async(}) qui exécute les tâches suivantes :
\begin{itemize}
	\item crée la requête
	\item encapsule la requête dans une tâche
	\item envoie la tâche au destinataire
\end{itemize}

Puis deux cas se présentent :
\begin{description}
	\item[Un accusé réception est attendu -]
	Cas des requêtes suivantes :
	\begin{itemize}
		\item {\tt BROADCAST} ( fonction {\tt broadcast()} )
		\item {\tt NEW\_BROTHER\_RCV} ( fonction {\tt connection\_request()} )
		\item {\tt DEL\_PRED} ( fonctions {\tt connect\_splitted\_groups()}, {\tt split()} )
		\item {\tt ADD\_PRED} ( fonction {\tt connect\_splitted\_groups()} )
		\item {\tt CNX\_GROUPS} ( fonction {\tt split()} )
	\end{itemize}

	L'émetteur empile alors la requête sur {\ti async\_answers} puis, lorsque plusieurs requêtes ont été émises,
	il appelle {\tt wait\_for\_completion()} pour arrêter le déroulement du programme jusqu'à ce que l'ensemble
	des accusés réception ait été reçu. \footnote{voir détails de {\tt wait\_for\_completion()} plus loin}
	C'est cette fonction qui dépile les requêtes de {\ti async\_answers} au fur et à mesure de leur réception
	et comme {\tt send\_msg\_sync()}, elle traite aussi tout ce qu'elle reçoit entre temps.


	\item[Pas d'accusé réception -]
	Dans ce cas, l'appelant ne fait qu'exécuter {\tt send\_msg\_async()}.
\end{description}


\subsubsection{En détails}
Voir figure \ref{sma} - page \pageref{sma}.

Cette fonction réalise la même chose que la première partie de {\tt send\_msg\_sync()}, à la différence qu'on
n'empile pas la requête puisqu'on laisse le soin à l'émetteur de décider s'il faut le faire ou pas.

Une autre différence est qu'on ignore un éventuel défaut d'émission ({\tt res != MSG\_OK}) alors que le
programme est arrêté dans {\tt send\_msg\_sync()}. Ce n'est pas volontaire, je n'ai juste pas encore étudié
la tolérance aux pannes.

\begin{figure}
    \centering
    \includegraphics[height=.95\textheight]{./Images/Algo_send_msg_async.png}
    \caption{Algo {\tt send\_msg\_async()}}
    \label{sma}
\end{figure}


\subsection{asynchrone - {\tt wait\_for\_completion()}}

Voir figure \ref{wfc} - page \pageref{wfc}.

On attend {\ti ans\_cpt} réponses. Si {\ti max\_wait} est atteint avant que toutes les réponses aient été reçues
et traitées, on quitte sur erreur, ce cas ne devant pas se produire.

{\tt wait\_for\_completion()} pouvant s'appeler elle-même, il faut commencer par vérifier si des réponses
attendues ont déjà été traitées par ces appels récursifs, et si oui, s'il en reste encore à traiter.
C'est l'appel à {\tt check\_async\_nok()} du début.

Si oui, on se met en écoute, et comme dans {\tt send\_msg\_sync()}, il faut traiter tout ce qui est reçu
dans l'intervalle:

\begin{description}

	\item[Requête:]

  Si c'est {\tt CNX\_REQ}, on l'empile sur {\ti tasks\_queue}, sinon, on l'exécute avec\\{\tt launch\_fork\_process()}.
  On regarde ensuite si des réponses ont été reçues entre temps avec {\tt check\_async\_nok()}, puis on se
  remet éventuellement en écoute.

	\item[Réponse:]\hfill
	
	\begin{itemize}[$\bullet$]

		\item Réponse asynchrone correspondant à une requête empilée :
		\begin{itemize}
			\item si elle fait partie de celles qui sont attendues, la requête correspondante est dépilée
           d'{\ti async\_answers}, après avoir mémorisé un éventuel échec de {\tt BROADCAST} ou {\tt SET\_UPDATE} dans {\ti ret}
           (pour du log).\footnote{On ne mémorise ici que le premier échec}
           On se remet ensuite en écoute s'il reste des réponses à recevoir. ({\tt ans\_cpt > 0})

           \item sinon, elle est enregistrée dans {\ti async\_answers}
    	\end{itemize}

		\item Réponse synchrone attendue :
		\begin{itemize}
	    	\item si oui, elle est enregistrée dans {\ti sync\_answers}
 			\item sinon, elle est ignorée.
    	\end{itemize}
    
    \end{itemize}
\end{description}
    
\begin{landscape}
\newgeometry{top=0cm, left=0cm, width=29.7cm, height=21cm}
\begin{figure}
    \centering
    \includegraphics[height=.99\textheight]{./Images/Algo_wait_for_completion.png}
    \caption{Algo {\tt wait\_for\_completion()}}
    \label{wfc}
\end{figure}
\restoregeometry
\end{landscape}

\subsection{asynchrone - {\tt check\_async\_nok()}}

Voir figure \ref{can} - page \pageref{can}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{./Images/Algo_check_async_nok.png}
    \caption{Algo {\tt check\_async\_nok()}}
    \label{can}
\end{figure}

Cette fonction auxiliaire est appelée par {\tt wait\_for\_completion()}. Elle est chargée de parcourir la file
{\ti async\_answers} à la recherche de réponses re\c cues.
Le cas échéant, la requête correspondante est retirée de la pile, le compteur de réponses attendues
{\ti ans\_cpt} est ajusté et on retourne également la dernière erreur re\c cue.

%***********************************************************************************************************************************

\chapter{Échec d'une diffusion d'un verrou : solution}

Parler du mécanisme de {\tt CS\_REQ}.

\end{document}