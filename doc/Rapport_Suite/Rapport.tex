RAPPEL
******

Déroulement des opérations pour l'insertion d'un nouveau noeud dans le DST: (sans équilibrage de
charge, pour simplfifier)
<DST_Arrival.png>


SITUATION
**********

A l'issue de nombreux tests, la première version de mon simulateur a montré son manque de robustesse
: lorsqu'un grand nombre de nouveaux arrivants impactent la même zone du DST à un même moment, les
choses se passent mal.
L'ensemble des problèmes observés semble pouvoir être ramené aux deux points suivants :

1) Le foisonnement des requêtes/réponses se passe mal
-----------------------------------------------------

Voici un exemple de cas de figure qui pose problème:

2 noeuds intègrent le DST via un même contact:
 * Node 14 --> Node 121 --> Node 42 (intégration rapide, pas de scission requise)
   puis
 * Node 249 --> Node 121 --> Node 42 (scissions et ajout d'étage requis)

 - Alors que Node 121 est en attente de ACK_CNX_REQ/249 de 42, il reçoit ACK_CNX_REQ/14 de 42. Il le
   stocke donc puisque ce n'est pas la réponse qu'il attend.

 - Node 14 ne recevant pas la réponse de 121 reste en 'b'.
   A ce stade de l'intégration, il fait déjà partie du DST et il reçoit donc ADD_STAGE/249 mais il
   ne peut y répondre ==> DEADLOCK

Comme on le voit, le fait que ACK_CNX_REQ/14 soit stocké par 121 pose problème ici.

Un seul process (hébergé sur Node 121) chargé de l'intégration de deux nouveaux noeuds différents
attend deux réponses. Le problème vient alors du fait qu'il ne peut pas traiter les réponses du
premier pendant qu'il est occupé avec le deuxième. Ce mécanisme n'est donc pas correct.

On pense alors à deux solutions possibles:
1) Utiliser la fonction MSG_comm_waitany() de Simgrid
   (elle permet de réagir à n'importe quelle réponse parmi celles qui sont attendues)
2) Utiliser plusieurs process dédiés, chacun gérant ses propres requêtes/réponses

La deuxième solution semble permettre de bien séparer les tâches, ce qui aurait un double avantage :
arrêter de mélanger les requêtes/réponses pour différents nouveaux arrivants, et présenter une
trace d'exécution plus lisible.

2) L'échec d'une diffusion d'un SET_UPDATE est mal géré
-------------------------------------------------------

Pour rappel, lorsque l'arrivée d'un nouveau noeud requiert des scissions, on diffuse un SET_UPDATE
sur l'ensemble du sous-arbre impacté dans le but de placer un verrou (l'état 'u') sur l'ensemble des
ces noeuds. Ainsi, ils ne peuvent plus s'occuper que des requêtes concernant cet ajout (les autres
sont soit refusées, soit différées).

Lorsque cette diffusion échoue (parce qu'on tombe sur une partie déjà verrouillée pour un autre
arrivant, par exemple), on se retrouve dans la situation où une partie du sous-arbre a été
verrouillée pour le nouveau noeud courant, et une autre pour un autre nouveau noeud. Il est donc
important de remettre les choses en état (ôter les verrous posés par la diffusion en échec) pour ne
pas bloquer les choses.

Les tests ont montré que la méthode utilisée pour cela n'est pas correcte puiqu'on arrive malgré
tout à générer des deadlocks. (ces deux sous-arbres se bloquent mutuellement)


Il faut donc trouver des solutions pour ces deux problèmes.

1) Présentation d'une solution au premier point
***********************************************

Voici les principes de base de cette solution :
  - Chaque demande d'insertion de nouveau noeud est traitée par un process distinct créé pour
    l'occasion
  - Ce sous-process ne peut pas recevoir de réponses à des requêtes qu'il n'a pas émises.
    Dit autrement, il doit (et peut) traiter immédiatement toutes les réponses reçues.
    (plus besoin de différer ou de refuser)
  - Plusieurs nouveaux noeuds utilisant le même contact ne pouvant pas être traités simultanément,
    un mécanisme de file d'attente pour les traiter séquentiellement est mis en place.

De plus, j'ai fait le choix d'utiliser aussi un tel sous-processus pour les diffusions de SPLIT et
de CS_REQ parce que là encore, cela semble être un avantage de ne pas mélanger les réponses
attendues dans le cas de diffusions croisées.

Voici donc le schéma général de cette solution à process multiples:

<Call_procs.png>

Remarque préliminaire:
launch_fork_process() est une fonction chargée de choisir comment exécuter les requêtes qui lui
sont transmises : elle les confie soit à un nouveau process (cas de CNX_REQ, BR_SPLIT, BR_CS_REQ),
soit au process courant.

On utilise au plus trois process par noeud:
    * Main_Proc:
      Comme son nom l'indique, c'est le process principal :
        - il se charge des initialisations et de la création du process Tasks_Queue (qui tourne
          tout le temps de la simulation).
        - il héberge les files tasks_queue (les CNX_REQ en attente) et delayed_tasks (les tâches
          différées)
        - lorsqu'il reçoit une requête, soit il la place dans la file tasks_queue (cas des
          CNX_REQ), soit il la transmet à launch_fork_process(). Il peut aussi différer des requêtes
          en les plaçant dans la file delayed_tasks (TODO : À VÉRIFIER)
        - il héberge ses propres files async_answers et sync_answers (les réponses asynchrones et
          synchrones attendues aux requêtes qu'il a émises)

    * Tasks_Queue:
      Ce process est chargé d'exécuter la fonction run_tasks_queue() qui traite les files
      tasks_queue et delayed_tasks.
      Il héberge aussi ses propres files async_answers et sync_answers.

    * Handle_Task:
      C'est ce process qui est éventuellement créé par launch_fork_process() pour traiter les
      requêtes concernées.
      Il héberge aussi ses propres files async_answers et sync_answers.

Dans le détail.
***************

run_tasks_queue
---------------

<Algo_run_tasks_queue.png>

La file tasks_queue contient toutes les demandes de connection (c'est à dire toutes les tâches
CNX_REQ) reçues par le noeud qui héberge cette file. run_tasks_queue() est donc chargée de traiter
les requêtes présentes dans cette file, par ordre de priorité.

Après avoir traité les tâches différées (voir détails run_delayed_tasks plus loin), on s'occupe de
la file tasks_queue proprement dite, à condition d'être actif (à l'état 'a').

Variable Run_state :
Chaque requête de cette file sera traitée par un process distinct, mais il n'est pas possible ici
d'insérer plus d'un nouveau noeud à la fois et il faut donc que ces process s'exécutent
séquentiellement. C'est la raison d'être de la variable de noeud Run_state : pour s'occuper de la
tâche suivante, la tâche courante doit être terminée. (valeur IDLE)

Variable Last_return :
Il y a deux sortes d'échec d'insertion possibles.
Lors de l'arrivée d'un nouveau noeud, on a la séquence d'appels suivante : nouveau noeud -->
contact --> leader. En cas d'échec, le contact doit refaire une tentive plus tard, mais son leader
peut avoir changé entre temps. Le leader doit donc dépiler la requête alors que le contact doit la
conserver dans la file. Deux valeurs de retour en cas d'échec sont alors requises : un leader
retourne la valeur FAILED alors qu'un contact retournera la valeur UPDATE_NOK.

Comme on peut le voir, une valeur de retour UPDATE_NOK laisse la requête dans la file pour une
nouvelle tentative un peu plus tard ("Sleep for a while"). Dans le cas contraire, on dépile pour
passer à la requête suivante.

Que la file soit dépilée ou pas, elle est à nouveau triée par ordre de priorité à ce moment-là. En
effet, pendant le temps d'exécution du CNX_REQ, d'autres demandes d'insertion ont pu arriver dans la
file et il faut s'assurer que la prochaine à exécuter soit bien la suivante en termes de priorité.

MAX_CNX ne sert qu'à afficher un message en cas de nombreuses tentatives d'exécution d'une même
requête.

L'exécution d'une requête de la file est confiée à launch_fork_process() (voir plus haut)


run_delayed_tasks
-----------------

<Algo_run_delayed_tasks.png> TODO : image à couper en deux ?

Cette fonction est chargée de traiter la file des tâches différées (delayed_tasks). Lorsqu'une tâche
ne peut pas être exécutée par un noeud, soit elle est refusée (et retournée à l'émetteur), soit
elle est stockée dans cette file pour être exécutée plus tard. Cette fonction est donc appelée
périodiquement. (Voir run_tasks_queue)

On distingue deux cas : soit le noeud courant est à l'état 'u', soit il est à 'a'.

1) état 'u'
-----------
Variables:
    - nb_elems : contient le nombre d'éléments de la file au lancement de run_delayed_tasks

    - cpt      : itérateur (de 0 à nb_elems)

Un nouveau noeud est alors en cours d'insertion et il faut examiner ce cas en premier pour minimiser
les risques de blocages.
Les seules tâches exécutables ici sont celles qui pourraient permettre de terminer cette insertion,
c'est à dire les CNX_GROUPS pour le même nouveau noeud que celui en cours d'insertion.
(c'est le test task_args.new_node_id == state.new_node_id)

On parcourt donc la file à la recherche de ces tâches pour les exécuter. (handle_task(task))

Lorsqu'on en trouve une, on peut l'ôter de la file sans s'assurer que son exécution a réussi ou pas
puisque si elle échoue, elle est à nouveau stockée dans la file.

A noter : à l'issue de la fonction handle_tasks, le nombre de tâches de la file a pu augmenter.
Pourant, on choisi de ne pas mettre à jour la variable nb_elems ici pour ne pas risquer une boucle
sans fin. Si des tâches ont été ajoutées entre temps, elles seront traitées lors d'une prochaine
exécution de run_delayed_tasks.

2) état 'a'
-----------
Ici, le noeud courant est prêt à exécuter n'importe quelle autre tâche et on peut passer au reste de
la file.

Variables:
    - nb_elems   :      le nombre d'éléments restants de la file.
                        N'est pas non plus remis à jour en cours de boucle.

    - idx        :      itérateur (de 0 à nb_elems)

    - is_contact :      vaut 1 si le noeud courant est le contact direct du nouveau noeud.
                        (autrement dit, si l'émetteur de la tâche à exécuter est le nouveau noeud)

    - buf_new_node_id : task_args.new_node_id est mémorisé dans cette variable parce qu'on en a besoin
                        après la destruction de task.

    On ôte la tâche courante de la file dans les cas suivants :
        - l'exécution a réussi (OK et UPDATE_OK)
        - la tâche a à nouveau été stockée (STORED)
        - l'exécution a échoué mais le noeud courant n'est pas le contact direct du nouveau noeud.
          (UPDATE_NOK && !is_contact)
          Il s'agit du cas FAILED décrit plus haut.

*********************************************************************
TODO : ne pourrait-on pas utiliser FAILED ici plutôt que is_contact ?
*********************************************************************

A noter : si le noeud courant était verrouillé pour le même nouveau noeud que
celui dont la tâche vient d'échouer, alors on ôte le verrou.

*****************
TODO : pourquoi ?
*****************

À l'issue de l'exécution de cette boucle (idx == nb_elems), la file n'est pas forcément vide. Elle
contient toutes les tâches dont l'exécution a échoué et celles qui ont été stockées par d'autres
process entre temps. Cette boucle est alors à nouveau exécutée jusqu'à ce que nb_elems soit à 0,
c'est dire jusqu'au succès de toutes les tâches qui se trouvaient dans cette file au moment de
cet appel de run_delayed_tasks. Comme indiqué précédemment, les tâches ajoutées entre temps ne
seront pas traitées lors de cette exécution.

*************************************************************************************************
TODO : se pourrait-il qu'il y ait un nouveau risque de boucle ici si une tâche échoue toujours ?
       ne faudrait-il pas repérer ce cas ?
*************************************************************************************************


launch_fork_process
-------------------

<Algo_launch_fork_process.png>

Si la tâche transmise à cette fonction n'est ni une demande de connexion (CNX_REQ), ni une
diffusion de SPLIT ou de CS_REQ, alors elle est exécutée localement, c'est à dire par le process
courant. Sinon, elle est confiée à un nouveau process créé pour l'occasion.

Remarques sur ce nouveau process:
--------------------------------
Il doit possèder ses propres file d'attente de réponses attendues (async_answers et sync_answers)
de sorte qu'elles ne puissent plus être mélangées avec celles requises pour l'insertion d'un autre
nouveau noeud.

Il est labelisé ainsi : xxx-nom_process-yyy où :
  - xxx est l'id du noeud courant
  - nom_process est le nom attribué par cette fonction (tel que "Cnx_req" ou "Br_split", etc)
  - yyy est l'id du nouveau noeud en cours d'insertion
On s'assure ainsi de l'unicité de l'étiquette de ce process.

Dans le cas où la tâche est une diffusion de CS_REQ (demande d'entrée en section critique), on
commence par s'assurer que le noeud courant est disponible (c'est à dire répondrait favorablement à
un CS_REQ) pour ne pas créer de process fils inutilement. En cas de non-disponibilité, il faut en
informer l'émetteur de la requête.

Description des fonctions de communication:
*******************************************
<Algo_send_msg_sync.png>  TODO : Algo à faire 

<Algo_recept_Send_Sync.png>
La fonction send_msg_sync() est chargée d'envoyer une requête à un autre noeud, puis d'en attendre
la réponse.
Cet algorithme présente cette partie d'attente de réponse.

Deux types de tâches peuvent être reçus :

1) Requête:
***********

Si c'est une CNX_REQ, on la place dans Tasks_Queue (voir algo run_tasks_queue), sinon, elle est
éxécutée. Si la réponse attendue n'a pas été reçue entre temps, on se remet en écoute. Sinon,
l'enregistrement correspondant est ôté de la file sync_answers et la réponse mémorisée.

2) Réponse:
***********
Si c'est la réponse attendue, même traitement que plus haut.
Sinon, s'il s'agit d'une des autres réponses synchrones ou asynchrones attendues, on l'inscrit dans
la file adéquate (sync_answers ou async_answsers, respectivement). Après quoi on se remet en écoute.

---------------------------------------------------

<Algo_recept_Wait.png>

**************************************
TODO : faire algo de check_async_nok ?
**************************************
