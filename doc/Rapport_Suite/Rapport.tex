RAPPEL
******

Déroulement des opérations pour l'insertion d'un nouveau noeud dans le DST: (sans équilibrage de
charge, pour simplfifier)
<DST_Arrival.png>


SITUATION
**********

A l'issue de nombreux tests, la première version de mon simulateur a montré son manque de robustesse
: lorsqu'un grand nombre de nouveaux arrivants impactent la même zone du DST à un même moment, les
choses se passent mal.
L'ensemble des problèmes observés semble pouvoir être ramené aux deux points suivants :

1) Le foisonnement des requêtes/réponses se passe mal
-----------------------------------------------------

Voici un exemple de cas de figure qui pose problème:

2 noeuds intègrent le DST via un même contact:
 * Node 14 --> Node 121 --> Node 42 (intégration rapide, pas de scission requise)
   puis
 * Node 249 --> Node 121 --> Node 42 (scissions et ajout d'étage requis)

 - Alors que Node 121 est en attente de ACK_CNX_REQ/249 de 42, il reçoit ACK_CNX_REQ/14 de 42. Il le
   stocke donc puisque ce n'est pas la réponse qu'il attend.

 - Node 14 ne recevant pas la réponse de 121 reste en 'b'.
   A ce stade de l'intégration, il fait déjà partie du DST et il reçoit donc ADD_STAGE/249 mais il
   ne peut y répondre ==> DEADLOCK

Comme on le voit, le fait que ACK_CNX_REQ/14 soit stocké par 121 pose problème ici.

Un seul process (hébergé sur Node 121) chargé de l'intégration de deux nouveaux noeuds différents
attend deux réponses. Le problème vient alors du fait qu'il ne peut pas traiter les réponses du
premier pendant qu'il est occupé avec le deuxième. Ce mécanisme n'est donc pas correct.

On pense alors à deux solutions possibles:
1) Utiliser la fonction MSG_comm_waitany() de Simgrid
   (elle permet de réagir à n'importe quelle réponse parmi celles qui sont attendues)
2) Utiliser plusieurs process dédiés, chacun gérant ses propres requêtes/réponses

La deuxième solution semble permettre de bien séparer les tâches, ce qui aurait un double avantage :
arrêter de mélanger les requêtes/réponses pour différents nouveaux arrivants, et présenter une
trace d'exécution plus lisible.

2) L'échec d'une diffusion d'un SET_UPDATE est mal géré
-------------------------------------------------------

Pour rappel, lorsque l'arrivée d'un nouveau noeud requiert des scissions, on diffuse un SET_UPDATE
sur l'ensemble du sous-arbre impacté dans le but de placer un verrou (l'état 'u') sur l'ensemble des
ces noeuds. Ainsi, ils ne peuvent plus s'occuper que des requêtes concernant cet ajout (les autres
sont soit refusées, soit différées).

Lorsque cette diffusion échoue (parce qu'on tombe sur une partie déjà verrouillée pour un autre
arrivant, par exemple), on se retrouve dans la situation où une partie du sous-arbre a été
verrouillée pour le nouveau noeud courant, et une autre pour un autre nouveau noeud. Il est donc
important de remettre les choses en état (ôter les verrous posés par la diffusion en échec) pour ne
pas bloquer les choses.

Les tests ont montré que la méthode utilisée pour cela n'est pas correcte puiqu'on arrive malgré
tout à générer des deadlocks. (ces deux sous-arbres se bloquent mutuellement)


Il faut donc trouver des solutions pour ces deux problèmes.

1) Présentation d'une solution au premier point
***********************************************

Voici les principes de base de cette solution :
  - Chaque demande d'insertion de nouveau noeud est traitée par un process distinct créé pour
    l'occasion
  - Ce sous-process ne peut pas recevoir de réponses à des requêtes qu'il n'a pas émises.
    Dit autrement, il doit (et peut) traiter immédiatement toutes les réponses reçues.
    (plus besoin de différer ou de refuser)
  - Plusieurs nouveaux noeuds utilisant le même contact ne pouvant pas être traités simultanément,
    un mécanisme de file d'attente pour les traiter séquentiellement est mis en place.

De plus, j'ai fait le choix d'utiliser aussi un tel sous-processus pour les diffusions de SPLIT et
de CS_REQ parce que là encore, cela semble être un avantage de ne pas mélanger les réponses
attendues dans le cas de diffusions croisées.

Voici donc le schéma général de cette solution à process multiples:

<Call_procs.png>

Remarque préliminaire:
launch_fork_process() est une fonction chargée de choisir comment exécuter les requêtes qui lui
sont transmises : elle les confie soit à un nouveau process (cas de CNX_REQ, BR_SPLIT, BR_CS_REQ),
soit au process courant.

On utilise au plus trois process par noeud:
    * Main_Proc:
      Comme son nom l'indique, c'est le process principal :
        - il se charge des initialisations et de la création du process Tasks_Queue (qui tourne
          tout le temps de la simulation).
        - il héberge les files tasks_queue (les CNX_REQ en attente) et delayed_tasks (les tâches
          différées)
        - lorsqu'il reçoit une requête, soit il la place dans la file tasks_queue (cas des
          CNX_REQ), soit il la transmet à launch_fork_process(). Il peut aussi différer des requêtes
          en les plaçant dans la file delayed_tasks (TODO : À VÉRIFIER)
        - il héberge ses propres files async_answers et sync_answers (les réponses asynchrones et
          synchrones attendues aux requêtes qu'il a émises)

    * Tasks_Queue:
      Ce process est chargé d'exécuter la fonction run_tasks_queue() qui traite les files
      tasks_queue et delayed_tasks.
      Il héberge aussi ses propres files async_answers et sync_answers.

    * Handle_Task:
      C'est ce process qui est éventuellement créé par launch_fork_process() pour traiter les
      requêtes concernées.
      Il héberge aussi ses propres files async_answers et sync_answers.

Dans le détail.
***************

run_tasks_queue
---------------

<Algo_run_tasks_queue.png>

La file tasks_queue contient toutes les demandes de connection (c'est à dire toutes les tâches
CNX_REQ) reçues par le noeud qui héberge cette file. run_tasks_queue() est donc chargée de traiter
les requêtes présentes dans cette file, par ordre de priorité.

Après avoir traité les tâches différées (voir détails run_delayed_tasks plus loin), on s'occupe de
la file tasks_queue proprement dite, à condition d'être actif (à l'état 'a').

Le noeud courant possède deux variables "de noeud" (c'est à dire globales à tous les process qui
tournent sur ce noeud) :

* Run_state :
Chaque requête de cette file sera traitée par un process distinct, mais il n'est pas possible ici
d'insérer plus d'un nouveau noeud à la fois et il faut donc que ces process s'exécutent
séquentiellement. C'est la raison d'être de cette variable Run_state : pour s'occuper de la tâche
suivante, la tâche courante doit être terminée. (valeur IDLE)

* Last_return :
Il y a deux sortes d'échec d'insertion possibles.
Lors de l'arrivée d'un nouveau noeud, on a la séquence d'appels suivante : nouveau noeud -->
contact --> leader. En cas d'échec, le contact doit refaire une tentive plus tard, mais son leader
peut avoir changé entre temps. Le leader doit donc dépiler la requête alors que le contact doit la
conserver dans la file. Deux valeurs de retour en cas d'échec sont alors requises : un leader
retourne la valeur FAILED alors qu'un contact retournera la valeur UPDATE_NOK.

Comme on peut le voir, dans le cas général (i.e. cpt < MAX_CNX), une valeur de retour UPDATE_NOK
laisse la requête dans la file pour une nouvelle tentative un peu plus tard ("Sleep for a while").
Dans le cas contraire, on dépile pour passer à la requête suivante. (On voit donc bien qu'en cas de
retour FAILED, la requête est bien dépilée.)

En détails :
À l'issue de l'exécution de connection_request(), une réponse est envoyée à l'émetteur seulement
dans les cas où la requête est ici dépilée.

Lors d'un échec, voici alors ce qu'il se passe dans la séquence de retour leader --> contact -->
nouveau noeud: le leader reçoit FAILED : il dépile sa requête et répond UPDATE_NOK à son contact.
Celui-ci ne dépile rien et ne répond pas à nouveau noeud. La requête restant dans la file s'exécutera
alors au plus MAX_CNX fois.

Si ce nombre est atteint, on décide alors de dépiler tout de même la requête et de répondre
UPDATE_NOK au nouveau noeud. Il peut ainsi détecter l'échec et refaire d'autres tentatives avec
d'autres contacts. (ces contacts sont alors choisis aléatoirement parmi les noeuds déjà intégrés au
DST. Il s'agit d'un tableau global, donc introduisant un peu de centralisation dans cet algorithme.
Voir commentaires en conclusion)

Que la file soit dépilée ou pas, elle est à nouveau triée par ordre de priorité à ce moment-là. En
effet, pendant le temps d'exécution de CNX_REQ, d'autres demandes d'insertion ont pu arriver dans la
file et il faut s'assurer que la prochaine à exécuter soit bien la suivante en termes de priorité.

L'exécution d'une requête de la file est confiée à launch_fork_process() (voir plus haut)

TODO : Ecrire algo de la partie TASK_CNX_REQ de handle_task()


run_delayed_tasks
-----------------

<Algo_run_delayed_tasks.png> TODO : image à couper en deux ?

Cette fonction est chargée de traiter la file des tâches différées (delayed_tasks). Lorsqu'une tâche
ne peut pas être exécutée par un noeud, soit elle est refusée (et retournée à l'émetteur), soit
elle est stockée dans cette file pour être exécutée plus tard. Cette fonction est donc appelée
périodiquement. (Voir run_tasks_queue)

On distingue deux cas : soit le noeud courant est à l'état 'u', soit il est à 'a'.

1) état 'u'
-----------
Variables:
    - nb_elems : contient le nombre d'éléments de la file au lancement de run_delayed_tasks

    - cpt      : itérateur (de 0 à nb_elems)

Un nouveau noeud est alors en cours d'insertion et il faut examiner ce cas en premier pour minimiser
les risques de blocages.
Les seules tâches exécutables ici sont celles qui pourraient permettre de terminer cette insertion,
c'est à dire les CNX_GROUPS pour le même nouveau noeud que celui en cours d'insertion.
(c'est le test task_args.new_node_id == state.new_node_id)

On parcourt donc la file à la recherche de ces tâches pour les exécuter. (handle_task(task))

Lorsqu'on en trouve une, on peut l'ôter de la file sans s'assurer que son exécution a réussi ou pas
puisque si elle échoue, elle est à nouveau stockée dans la file.

A noter : à l'issue de la fonction handle_tasks, le nombre de tâches de la file a pu augmenter.
Pourant, on choisi de ne pas mettre à jour la variable nb_elems ici pour ne pas risquer une boucle
sans fin. Si des tâches ont été ajoutées entre temps, elles seront traitées lors d'une prochaine
exécution de run_delayed_tasks.

2) état 'a'
-----------
Ici, le noeud courant est prêt à exécuter n'importe quelle autre tâche et on peut passer au reste de
la file.

Variables:
    - nb_elems   :      le nombre d'éléments restants de la file.
                        N'est pas non plus remis à jour en cours de boucle.

    - idx        :      itérateur (de 0 à nb_elems)

    - is_contact :      vaut 1 si le noeud courant est le contact direct du nouveau noeud.
                        (autrement dit, si l'émetteur de la tâche à exécuter est le nouveau noeud)

    - buf_new_node_id : task_args.new_node_id est mémorisé dans cette variable parce qu'on en a besoin
                        après la destruction de task.

    On ôte la tâche courante de la file dans les cas suivants :
        - l'exécution a réussi (OK et UPDATE_OK)
        - la tâche a à nouveau été stockée (STORED)
        - l'exécution a échoué mais le noeud courant n'est pas le contact direct du nouveau noeud.
          (UPDATE_NOK && !is_contact)
          Il s'agit du cas FAILED décrit plus haut.

*********************************************************************
TODO : ne pourrait-on pas utiliser FAILED ici plutôt que is_contact ?
*********************************************************************

A noter : si le noeud courant était verrouillé pour le même nouveau noeud que
celui dont la tâche vient d'échouer, alors on ôte le verrou.

*****************
TODO : pourquoi ?
*****************

À l'issue de l'exécution de cette boucle (idx == nb_elems), la file n'est pas forcément vide. Elle
contient toutes les tâches dont l'exécution a échoué et celles qui ont été stockées par d'autres
process entre temps. Cette boucle est alors à nouveau exécutée jusqu'à ce que nb_elems soit à 0,
c'est dire jusqu'au succès de toutes les tâches qui se trouvaient dans cette file au moment de
cet appel de run_delayed_tasks. Comme indiqué précédemment, les tâches ajoutées entre temps ne
seront pas traitées lors de cette exécution.

*************************************************************************************************
TODO : se pourrait-il qu'il y ait un nouveau risque de boucle ici si une tâche échoue toujours ?
       ne faudrait-il pas repérer ce cas ?
*************************************************************************************************


launch_fork_process
-------------------

<Algo_launch_fork_process.png>

Si la tâche transmise à cette fonction n'est ni une demande de connexion (CNX_REQ), ni une
diffusion de SPLIT ou de CS_REQ, alors elle est exécutée localement, c'est à dire par le process
courant. Sinon, elle est confiée à un nouveau process créé pour l'occasion.

Ce nouveau process doit possèder ses propres files d'attente de réponses attendues (async_answers et
sync_answers) de sorte qu'elles ne puissent plus être mélangées avec celles requises pour l'insertion
d'un autre nouveau noeud.

Il est labelisé ainsi : xxx-nom_process-yyy où :
  - xxx est l'id du noeud courant
  - nom_process est le nom attribué par cette fonction (tel que "Cnx_req" ou "Br_split", etc)
  - yyy est l'id du nouveau noeud en cours d'insertion
On s'assure ainsi de l'unicité de l'étiquette de ce process.

Dans le cas où la tâche est une diffusion de CS_REQ (demande d'entrée en section critique), on
commence par s'assurer que le noeud courant est disponible (c'est à dire répondrait favorablement à
un CS_REQ) pour ne pas créer de process fils inutilement. En cas de non-disponibilité, il faut en
informer l'émetteur de la requête.

Description des fonctions de communication:
*******************************************

Différence entre requêtes synchrones et asynchrones :
*****************************************************

Synchrone :
***********

La requête synchrone est utilisée lorsqu'une réponse est attendue pour poursuivre l'exécution du
programme.

Cas d'emplois principaux:
(pour simplifier, la phase d'équilibrage de charge est ignorée ici)

- CNX_REQ ( fonction join() )
  La réponse attendue est la table de routage du contact qui a réussi l'insertion du nouveau noeud

- BROADCAST ( fonction handle_task():BROADCAST )
  La réponse attendue ici est la valeur de retour de la fonction handle_task(), c'est à dire le succès
  ou l'échec de la requête diffusée.

De plus, on utilise aussi ce type de requête pour retransmettre au leader les requêtes CNX_REQ et
SPLIT_REQ. (pas forcément utile dans le cas de SPLIT_REQ, à voir)

L'attente de la réponse ne devant pas être bloquante, toutes les requêtes ou autres réponses
arrivant dans l'intervalle doivent être traitées.

Déroulement simplifié des opérations : (voir détails plus loin)
L'émetteur de la requête appelle send_msg_sync() qui exécute les tâches suivantes :
- crée la requête
- encapsule la requête dans une tâche
- empile la requête sur sync_answers
- envoie la tâche au destinataire
- attend la réponse
- traite tout ce qui est reçu qui n'est pas la réponse
- dès que la réponse est reçue, dépile la requête de sync_answers
- retourne la réponse à l'appelant


Asynchrone :
************

Dans ce type de requête, le destinataire renvoie un simple accusé réception à l'émetteur une fois la
requête demandée effectuée. Ces accusés réception seront pris en compte ou pas selon les besoins de
synchronisation.

Dans les deux cas, les opération se déroulent de cette façon :

L'émetteur appelle send_msg_async() qui exécute les tâches suivantes : (voir détails plus loin)
- crée la requête
- encapsule la requête dans une tâche
- envoie la tâche au destinataire

Puis deux cas se présentent :

1er cas : Un accusé réception est attendu
-----------------------------------------

Cas des requêtes suivantes :

- BROADCAST ( fonction broadcast() )
- NEW_BROTHER_RCV ( fonction connection_request() )
- DEL_PRED ( fonctions connect_splitted_groups(), split() )
- ADD_PRED ( fonction connect_splitted_groups() )
- CNX_GROUPS ( fonction split() )

L'émetteur empile alors la requête sur async_answers puis, lorsque plusieurs requêtes ont été émises,
il appelle wait_for_completion() pour arrêter le déroulement du programme jusqu'à ce que l'ensemble
des accusés réception ait été reçu. (voir détails de wait_for_completion plus loin)
C'est cette fonction qui dépile les requêtes de async_answers au fur et à mesure de leur réception
et comme send_msg_sync(), elle traite aussi tout ce qu'elle reçoit entre temps.


2e cas : pas d'accusé réception
-------------------------------

Dans ce cas, l'appelant ne fait qu'exécuter send_msg_async().


send_msg_sync() en détails:
***************************

<Algo_send_msg_sync.png>

La fonction send_msg_sync() est chargée d'envoyer une requête à un autre noeud, puis d'en attendre
la réponse.

Introduction : Chaque process hébergé par un noeud possède deux files : sync_answers et async_answers.
**************
Ces deux files servent à stocker les requêtes synchrones et asynchrones (respectivement) en attente
de réponse, ainsi que leur réponse, dès qu'elle a été reçue. Ces requêtes sont dépilées dès que leur
réponse a été prise en compte.
Pour mémoire, la réponse à une requête synchrone contient les données demandées alors que la réponse
à une requête asynchrone est simplement un accusé réception.

Lorqu'une réponse est reçue, il y a trois cas possibles :
- il s'agit de la réponse qu'on est en train d'attendre :
  Dans ce cas, la réponse est prise en compte, la requête correspondante est simplement dépilée et
  le traitement se poursuit.

- il s'agit d'une autre réponse attendue :
  Elle est alors enregistrée dans la bonne pile, avec la requête correspondante

- il ne s'agit d'aucune réponse attendue :
  Elle est simplement ignorée (cas de certains accusés réception, par exemple)

Déroulement de l'algo:
**********************

Première partie : envoi de la requête.
***************************************

Après avoir construit la tâche contenant la requête, celle-ci est envoyée au moyen de la fonction
isend() de Simgrid, puis stockée dans la pile sync_answers du process courant.
On attend ensuite la fin de la communication.

Deux traitements différents des cas d'échecs :
- la communication ne se termine pas (cas du process destinataire arrêté) ou elle a le statut
  MSG_TRANSFER_FAILURE (cas de l'hôte destinataire arrêté) :
  La fonction s'arrête en retourant une erreur de transmission.

- la communication se termine avec le statut TIMEOUT ( cas d'un destinataire trop occupé, par
  exemple ) :
  On recommence l'émission un certain nombre de fois (loop_cpt).
  Si max_loops est atteint, la fonction est également arrêtée avec une erreur de transmission.


Deuxième partie : réception de la réponse
*****************************************

Dans cette partie, le process courant se met en écoute de la réponse. En cas d'erreur de communication
( res != MSG_OK ), on la signale et on se remet en écoute, sauf s'il s'agit d'un TIMEOUT pour une
requête GET_REP. Dans ce cas, on arrête la fonction là en retournant simplement l'erreur pour la
signaler à l'appelant.

GET_REP est traitée de cette façon pour supprimer une possibilité de deadlock. GET_REP demande à un
noeud de fournir un autre représentant moins chargé pour un étage donné. S'il met trop de temps à
répondre et qu'on abandonne, ça n'a pas d'autre conséquence que de conserver le même représentant.
L'équilibrage de charge n'est alors pas optimumn, mais on accepte de défaut pour l'instant.

Deux types de tâches peuvent être reçus : soit une requête, soit une réponse.

* Cas d'une requête :
  Si c'est une demande de connexion (CNX_REQ), elle est simplement stockée dans tasks_queue (
  rappel : cette file est hébergée par le noeud courant ).
  Sinon, on l'exécute avec handle_task. ( TODO : pourquoi pas launch_fork_process ? )

  Ensuite, on regarde dans la pile sync_answers pour voir si la réponse attendue n'a pas été reçue
  entre temps. Si oui, elle est dépilée et on quitte la boucle de réception. Sinon, on se remet en
  écoute.

* Cas d'une réponse :
  On commence par regarder s'il s'agit de la réponse synchrone attendue. Si oui, elle est dépilée et
  on quitte la boucle de réception.
  Sinon, il peut s'agir d'une autre réponse attendue (synchrone ou asynchrone). Autrement dit, la
  requête correspondante à cette réponse est trouvée dans une des deux piles sync_answers ou
  async_answers.
  Dans ce cas, la réponse est enregistrée avec sa requête dans sa pile et on se remet en écoute.
  S'il ne s'agit d'aucune réponse attendue, on peut l'ignorer simplement et se remettre en écoute.

Remarques :
***********

1)
Dans cette fonction, la requête en attente de réponse se trouve toujours au sommet de la pile :
un process donné ne peut exécuter qu'une seule instance de send_msg_sync() à la fois, send_msg_sync()
est la seule fonction susceptible d'empiler une requête dans sync_answers, et une pile sync_answers
n'est associée qu'à un seul process.
De ce fait, lorsqu'on reçoit une réponse à une requête synchrone attendue, il est facile de déterminer
s'il s'agit de la réponse attendue ou d'une autre : la requête est au sommet de la pile ou pas.

2)
Si send_msg_sync() n'est pas appelée par le process principal, elle ne peut pas recevoir d'autre
message que celui qui est attendu.

---------------------------------------------------


send_msg_async() en détails
***************************

<Algo_send_msg_async.png>

Cette fonction réalise la même chose que la première partie de send_msg_syn(), à la différence qu'on
n'empile pas la requête puisqu'on laisse le soin à l'émetteur de décider s'il faut le faire ou pas.

Une autre différence est qu'on ignore un éventuel défaut d'émission (res != MSG_OK) alors que le
programme est arrêté dans send_msg_sync(). Ce n'est pas volontaire, je n'ai juste pas encore étudié
la tolérance aux pannes.


wait_for_completion() en détails
********************************

<Algo_wait_for_completion.png>

On attend ans_cpt réponses. Si max_wait est atteint avant que toutes les réponses aient été reçues
et traitées, on quitte sur erreur, ce cas ne devant pas se produire.

wait_for_completion() pouvant s'appeler elle-même, il faut commencer par vérifier si des réponses
attendues ont déjà été traitées par ces appels récursifs, et si oui, s'il en reste encore à traiter.
C'est l'appel à check_async_nok() du début.

Si oui, on se met en écoute, et comme dans send_msg_sync(), il faut traiter tout ce qui est reçu
dans l'intervalle.

- Requête:
  ********

  Si c'est CNX_REQ, on l'empile sur tasks_queue, sinon, on l'exécute avec launch_fork_process().
  On regarde ensuite si des réponses ont été reçues entre temps avec check_async_nok(), puis on se
  remet éventuellement en écoute.

- Réponse:
  ********

  - Réponse asynchrone correspondant à une requête empilée :
    - si elle fait partie de celles qui sont attendues, la requête correspondante est dépilée
    d'async_answers, après avoir mémorisé un éventuel échec de BROADCAST ou SET_UPDATE dans ret
    (pour du log)
    On se remet ensuite en écoute s'il reste des réponses à recevoir. (ans_cpt > 0)

    - sinon, elle est enregistrée dans async_answers

  - Réponse synchrone attendue :
    - si oui, elle est enregistrée dans sync_answers
    - sinon, elle est ignorée.


**************************************
TODO : faire algo de check_async_nok
**************************************
